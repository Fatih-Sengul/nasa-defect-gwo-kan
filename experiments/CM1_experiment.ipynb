{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ NASA Defect Prediction: CM1\n",
    "\n",
    "**Dataset:** CM1\n",
    "**Method:** Baseline RF â†’ KAN Base â†’ KAN + Attention\n",
    "**Goal:** F2 & Recall optimization (defect detection)\n",
    "\n",
    "**âœ… Self-contained:** Run all cells in order, no dependencies!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 1: Setup & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('âœ… Google Drive mounted!')\n",
    "except ImportError:\n",
    "    print('âš ï¸  Not on Colab - skipping mount')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install imbalanced-learn scipy scikit-learn torch matplotlib seaborn pandas numpy openpyxl -q\n",
    "print('âœ… Packages installed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from io import StringIO\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    fbeta_score, confusion_matrix, average_precision_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print('âœ… Imports complete!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATASET_NAME = 'CM1'\n",
    "DATASET_PATH = '/content/drive/MyDrive/nasa-defect-gwo-kan/dataset'\n",
    "OUTPUT_DIR = f'./results_{DATASET_NAME}'\n",
    "SEED = 42\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device('cpu')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "RUN_ID = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "print(f'âœ… Configuration complete!')\n",
    "print(f'ðŸ“Š Dataset: CM1')\n",
    "print(f'ðŸ–¥ï¸  Device: {device}')\n",
    "print(f'ðŸ“ Output: {OUTPUT_DIR}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Step 2: Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Utility functions for data loading and metrics\n\ndef load_arff(file_path):\n    \"\"\"Load ARFF file and return pandas DataFrame.\"\"\"\n    try:\n        data, _ = arff.loadarff(file_path)\n        df = pd.DataFrame(data)\n        for col in df.columns:\n            if df[col].dtype == object:\n                try:\n                    df[col] = df[col].str.decode('utf-8')\n                except:\n                    pass\n        return df\n    except:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n        data_start = content.lower().find('@data')\n        data_section = content[data_start + 5:].strip()\n        return pd.read_csv(StringIO(data_section), header=None)\n\ndef calc_metrics(y_true, y_pred, y_proba=None):\n    \"\"\"Calculate comprehensive metrics for defect prediction.\"\"\"\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n    m = {\n        'recall': recall_score(y_true, y_pred, zero_division=0),\n        'precision': precision_score(y_true, y_pred, zero_division=0),\n        'f1': f1_score(y_true, y_pred, zero_division=0),\n        'f2': fbeta_score(y_true, y_pred, beta=2, zero_division=0),\n        'accuracy': accuracy_score(y_true, y_pred),\n        'tp': int(tp), 'fp': int(fp), 'tn': int(tn), 'fn': int(fn)\n    }\n    if y_proba is not None:\n        try:\n            m['pr_auc'] = average_precision_score(y_true, y_proba)\n        except:\n            m['pr_auc'] = 0.0\n    else:\n        m['pr_auc'] = 0.0\n    return m\n\ndef find_threshold(y_true, y_proba):\n    \"\"\"Find optimal threshold for F2 score.\"\"\"\n    best_score, best_t = -1, 0.5\n    for t in np.arange(0.05, 0.96, 0.05):\n        y_pred = (y_proba >= t).astype(int)\n        m = calc_metrics(y_true, y_pred)\n        score = m['f2'] if m['accuracy'] >= 0.5 else 0\n        if score > best_score:\n            best_score, best_t = score, t\n    return best_t\n\ndef find_balanced_threshold(y_true, y_proba, target_recall=0.875):\n    \"\"\"Find threshold with GUARANTEED recall while maximizing other metrics.\n    \n    Strategy: Recall is NON-NEGOTIABLE! Among all thresholds that achieve \n    target recall, pick the one with best precision/accuracy/F2.\n    \"\"\"\n    best_score = -1\n    best_threshold = 0.5\n    best_metrics = None\n    \n    print(f'   ðŸ” Searching thresholds with MANDATORY Recall â‰¥ {target_recall:.3f}...')\n    \n    # Fine-grained search from very low to moderate thresholds\n    for t in np.arange(0.10, 0.50, 0.005):  # 0.005 step = 80 candidates!\n        y_pred = (y_proba >= t).astype(int)\n        m = calc_metrics(y_true, y_pred, y_proba)\n        \n        # HARD CONSTRAINT: Recall MUST be >= target_recall\n        if m['recall'] < target_recall:\n            continue  # Skip this threshold completely!\n        \n        # Among thresholds that meet recall target, maximize other metrics:\n        # 40% F2 (recall-weighted, important for defect detection)\n        # 30% Precision (reduce false positives)\n        # 30% Accuracy (overall quality)\n        score = (\n            0.40 * m['f2'] + \n            0.30 * m['precision'] + \n            0.30 * m['accuracy']\n        )\n        \n        # Secondary soft constraint: prefer reasonable accuracy\n        if m['accuracy'] >= 0.55 and score > best_score:\n            best_score = score\n            best_threshold = t\n            best_metrics = m\n    \n    # Fallback: if no threshold gives target recall with acc>=0.55, \n    # just take the best one with target recall (ignore accuracy)\n    if best_metrics is None:\n        print(f'   âš ï¸  No threshold with Accâ‰¥0.55, relaxing accuracy constraint...')\n        for t in np.arange(0.10, 0.50, 0.005):\n            y_pred = (y_proba >= t).astype(int)\n            m = calc_metrics(y_true, y_pred, y_proba)\n            \n            # Still require target recall!\n            if m['recall'] < target_recall:\n                continue\n            \n            score = 0.40 * m['f2'] + 0.30 * m['precision'] + 0.30 * m['accuracy']\n            \n            if score > best_score:\n                best_score = score\n                best_threshold = t\n                best_metrics = m\n    \n    # Ultimate fallback: slightly lower recall target\n    if best_metrics is None:\n        print(f'   âš ï¸  Relaxing recall to â‰¥ 0.85...')\n        for t in np.arange(0.10, 0.50, 0.005):\n            y_pred = (y_proba >= t).astype(int)\n            m = calc_metrics(y_true, y_pred, y_proba)\n            \n            if m['recall'] < 0.85:\n                continue\n            \n            score = 0.40 * m['f2'] + 0.30 * m['precision'] + 0.30 * m['accuracy']\n            \n            if score > best_score:\n                best_score = score\n                best_threshold = t\n                best_metrics = m\n    \n    # Final fallback: maximize F2 if all else fails\n    if best_metrics is None:\n        print(f'   âš ï¸  Using F2-maximization fallback...')\n        for t in np.arange(0.15, 0.45, 0.01):\n            y_pred = (y_proba >= t).astype(int)\n            m = calc_metrics(y_true, y_pred, y_proba)\n            \n            if m['f2'] > best_score:\n                best_score = m['f2']\n                best_threshold = t\n                best_metrics = m\n    \n    return best_threshold\n\nprint('âœ… Utility functions defined!')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Step 3: Define KAN Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KANLinear: Core KAN layer with spline-based activation\n",
    "\n",
    "class KANLinear(nn.Module):\n",
    "    \"\"\"Kolmogorov-Arnold Network Linear Layer with learnable spline activations.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, grid_size=3, spline_order=2):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.grid_size = grid_size\n",
    "        self.spline_order = spline_order\n",
    "        \n",
    "        # Learnable grid points\n",
    "        self.grid = nn.Parameter(\n",
    "            torch.linspace(-1, 1, grid_size)\n",
    "            .unsqueeze(0).unsqueeze(0)\n",
    "            .repeat(out_features, in_features, 1)\n",
    "        )\n",
    "        \n",
    "        # Spline coefficients\n",
    "        self.coef = nn.Parameter(\n",
    "            torch.randn(out_features, in_features, grid_size + spline_order) * 0.1\n",
    "        )\n",
    "        \n",
    "        # Base weights\n",
    "        self.base_weight = nn.Parameter(\n",
    "            torch.randn(out_features, in_features) * 0.1\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Expand input for broadcasting\n",
    "        x_expanded = x.unsqueeze(1).unsqueeze(-1)  # [B, 1, in_f, 1]\n",
    "        \n",
    "        # Compute distances to grid points\n",
    "        distances = torch.abs(x_expanded - self.grid.unsqueeze(0))\n",
    "        \n",
    "        # Build basis functions\n",
    "        basis = torch.zeros(\n",
    "            batch_size, self.out_features, self.in_features,\n",
    "            self.grid_size + self.spline_order,\n",
    "            device=x.device\n",
    "        )\n",
    "        \n",
    "        # RBF basis for grid points\n",
    "        for i in range(self.grid_size):\n",
    "            basis[:, :, :, i] = torch.exp(-distances[:, :, :, i] ** 2 / 0.5)\n",
    "        \n",
    "        # Polynomial basis\n",
    "        for i in range(self.spline_order):\n",
    "            basis[:, :, :, self.grid_size + i] = x_expanded.squeeze(-1) ** (i + 1)\n",
    "        \n",
    "        # Compute spline output\n",
    "        spline_output = (basis * self.coef.unsqueeze(0)).sum(dim=-1).sum(dim=-1)\n",
    "        \n",
    "        # Add base transformation\n",
    "        base_output = torch.matmul(x, self.base_weight.t())\n",
    "        \n",
    "        return spline_output + base_output\n",
    "\n",
    "print('âœ… KANLinear layer defined!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# KAN: Complete KAN model for defect prediction\n\nclass KAN(nn.Module):\n    \"\"\"Kolmogorov-Arnold Network for binary defect classification.\"\"\"\n    \n    def __init__(self, input_dim, hidden_dim=64, grid_size=5, spline_order=3):\n        super().__init__()\n        # Deeper architecture with 3 KAN layers\n        self.kan1 = KANLinear(input_dim, hidden_dim, grid_size, spline_order)\n        self.kan2 = KANLinear(hidden_dim, hidden_dim, grid_size, spline_order)\n        self.kan3 = KANLinear(hidden_dim, hidden_dim // 2, grid_size, spline_order)\n        self.output_layer = nn.Linear(hidden_dim // 2, 1)\n        \n        self.bn1 = nn.BatchNorm1d(hidden_dim)\n        self.bn2 = nn.BatchNorm1d(hidden_dim)\n        self.bn3 = nn.BatchNorm1d(hidden_dim // 2)\n        self.dropout = nn.Dropout(0.2)\n    \n    def forward(self, x):\n        x = self.kan1(x)\n        x = self.bn1(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n        \n        x = self.kan2(x)\n        x = self.bn2(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n        \n        x = self.kan3(x)\n        x = self.bn3(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n        \n        x = self.output_layer(x)\n        return torch.sigmoid(x)\n\nprint('âœ… KAN model defined!')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Multi-Head Attention and Enhanced KAN with Attention\n\nclass MultiHeadAttention(nn.Module):\n    \"\"\"Multi-head attention mechanism for feature importance.\"\"\"\n    \n    def __init__(self, input_dim, num_heads=4, attention_dim=32):\n        super().__init__()\n        self.num_heads = num_heads\n        self.attention_dim = attention_dim\n        \n        # Multiple attention heads\n        self.heads = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(input_dim, attention_dim),\n                nn.ReLU(),\n                nn.Dropout(0.1),\n                nn.Linear(attention_dim, input_dim),\n                nn.Sigmoid()\n            ) for _ in range(num_heads)\n        ])\n        \n        # Combine heads\n        self.combine = nn.Linear(input_dim * num_heads, input_dim)\n        self.layer_norm = nn.LayerNorm(input_dim)\n    \n    def forward(self, x):\n        # Apply all attention heads\n        attended_outputs = []\n        for head in self.heads:\n            attention_weights = head(x)\n            attended_outputs.append(x * attention_weights)\n        \n        # Concatenate and combine\n        combined = torch.cat(attended_outputs, dim=-1)\n        output = self.combine(combined)\n        \n        # Residual connection + layer norm\n        output = self.layer_norm(x + output)\n        \n        return output\n\n\nclass KAN_Attention(nn.Module):\n    \"\"\"Enhanced KAN with Multi-Head Attention for superior defect detection.\"\"\"\n    \n    def __init__(self, input_dim, hidden_dim=128, grid_size=5, spline_order=3):\n        super().__init__()\n        \n        # Multi-head attention with 4 heads\n        self.attention = MultiHeadAttention(input_dim, num_heads=4, attention_dim=64)\n        \n        # Deeper KAN architecture - 4 layers\n        self.kan1 = KANLinear(input_dim, hidden_dim, grid_size, spline_order)\n        self.kan2 = KANLinear(hidden_dim, hidden_dim, grid_size, spline_order)\n        self.kan3 = KANLinear(hidden_dim, hidden_dim // 2, grid_size, spline_order)\n        self.kan4 = KANLinear(hidden_dim // 2, hidden_dim // 4, grid_size, spline_order)\n        \n        # Batch normalization for each layer\n        self.bn1 = nn.BatchNorm1d(hidden_dim)\n        self.bn2 = nn.BatchNorm1d(hidden_dim)\n        self.bn3 = nn.BatchNorm1d(hidden_dim // 2)\n        self.bn4 = nn.BatchNorm1d(hidden_dim // 4)\n        \n        # Dropout for regularization\n        self.dropout1 = nn.Dropout(0.2)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dropout3 = nn.Dropout(0.15)\n        self.dropout4 = nn.Dropout(0.1)\n        \n        # Output layer\n        self.output_layer = nn.Linear(hidden_dim // 4, 1)\n        \n        # Feature importance tracking\n        self.feature_importance = None\n    \n    def forward(self, x):\n        # Apply multi-head attention with residual\n        x_attended = self.attention(x)\n        \n        # Deep KAN layers with residual connections\n        x1 = self.kan1(x_attended)\n        x1 = self.bn1(x1)\n        x1 = F.relu(x1)\n        x1 = self.dropout1(x1)\n        \n        x2 = self.kan2(x1)\n        x2 = self.bn2(x2)\n        x2 = F.relu(x2)\n        x2 = self.dropout2(x2)\n        \n        # Residual connection from x1 to x2\n        x2 = x2 + x1\n        \n        x3 = self.kan3(x2)\n        x3 = self.bn3(x3)\n        x3 = F.relu(x3)\n        x3 = self.dropout3(x3)\n        \n        x4 = self.kan4(x3)\n        x4 = self.bn4(x4)\n        x4 = F.relu(x4)\n        x4 = self.dropout4(x4)\n        \n        # Final prediction\n        output = self.output_layer(x4)\n        return torch.sigmoid(output)\n\nprint('âœ… Multi-Head Attention and Enhanced KAN_Attention defined!')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Advanced Loss Functions for Defect Detection\n\nclass FocalLoss(nn.Module):\n    \"\"\"Focal Loss to handle class imbalance.\"\"\"\n    \n    def __init__(self, alpha=0.25, gamma=2.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n    \n    def forward(self, inputs, targets):\n        bce_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-bce_loss)\n        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n        return focal_loss.mean()\n\n\nclass RecallFocusedLoss(nn.Module):\n    \"\"\"Custom loss that heavily penalizes false negatives (missed defects).\"\"\"\n    \n    def __init__(self, alpha=0.9, fn_penalty=10.0):\n        super().__init__()\n        self.alpha = alpha\n        self.fn_penalty = fn_penalty\n    \n    def forward(self, inputs, targets):\n        # Standard BCE\n        bce = F.binary_cross_entropy(inputs, targets, reduction='none')\n        \n        # Extra penalty for false negatives (targets=1, inputs<0.5)\n        fn_mask = (targets == 1).float()\n        fn_penalty = fn_mask * (1 - inputs) * self.fn_penalty\n        \n        # Combine losses\n        total_loss = bce + fn_penalty\n        \n        # Weight positive class more\n        weights = targets * self.alpha + (1 - targets) * (1 - self.alpha)\n        weighted_loss = total_loss * weights\n        \n        return weighted_loss.mean()\n\nprint('âœ… Advanced Loss Functions defined!')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 4: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print('\\n' + '='*70)\n",
    "print('ðŸš€ LOADING DATASET: CM1')\n",
    "print('='*70 + '\\n')\n",
    "\n",
    "file_path = os.path.join(DATASET_PATH, 'CM1.arff')\n",
    "df = load_arff(file_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.iloc[:, :-1].values.astype(np.float32)\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Encode labels if needed\n",
    "if y.dtype == object:\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "else:\n",
    "    y = y.astype(int)\n",
    "\n",
    "print(f'âœ… Dataset loaded successfully!')\n",
    "print(f'   Total samples: {len(y)}')\n",
    "print(f'   Features: {X.shape[1]}')\n",
    "print(f'   Defective samples: {np.sum(y==1)} ({np.mean(y==1):.2%})')\n",
    "print(f'   Non-defective samples: {np.sum(y==0)} ({np.mean(y==0):.2%})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (NaN imputation)\n",
    "if np.any(np.isnan(X)):\n",
    "    print('âš ï¸  Found NaN values, imputing with column medians...')\n",
    "    col_medians = np.nanmedian(X, axis=0)\n",
    "    nan_indices = np.where(np.isnan(X))\n",
    "    X[nan_indices] = np.take(col_medians, nan_indices[1])\n",
    "    print('âœ… NaN values imputed!')\n",
    "else:\n",
    "    print('âœ… No NaN values found!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (train/val/test) - leakage-free splits\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=SEED\n",
    ")\n",
    "\n",
    "print('âœ… Data split complete!')\n",
    "print(f'   Training samples: {len(y_train)}')\n",
    "print(f'   Validation samples: {len(y_val)}')\n",
    "print(f'   Test samples: {len(y_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (fit on train, transform all sets)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print('âœ… Feature scaling complete!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Apply SMOTE to training data only (prevent data leakage)\nsmote = SMOTE(sampling_strategy=1.0, random_state=SEED)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\nprint('âœ… SMOTE resampling complete!')\nprint(f'   Before: {len(y_train)} samples')\nprint(f'   After: {len(y_train_resampled)} samples')\nprint(f'   Added: {len(y_train_resampled) - len(y_train)} synthetic samples')\nprint(f'   Class balance: {np.sum(y_train_resampled==1)}/{np.sum(y_train_resampled==0)} (defective/normal)')\n\n# Initialize results dictionary\nresults = {}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒ² Step 5: Train Baseline Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline Random Forest classifier\n",
    "print('\\n' + '='*70)\n",
    "print('ðŸŒ² TRAINING BASELINE: RANDOM FOREST')\n",
    "print('='*70 + '\\n')\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    class_weight='balanced',\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "print('âœ… Random Forest training complete!')\n",
    "\n",
    "# Find optimal threshold on validation set\n",
    "y_val_proba_rf = rf_model.predict_proba(X_val)[:, 1]\n",
    "threshold_rf = find_threshold(y_val, y_val_proba_rf)\n",
    "print(f'   Optimal threshold: {threshold_rf:.2f}')\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred_rf = (y_test_proba_rf >= threshold_rf).astype(int)\n",
    "metrics_rf = calc_metrics(y_test, y_test_pred_rf, y_test_proba_rf)\n",
    "\n",
    "print(f'\\nðŸ“Š Test Set Results:')\n",
    "print(f'   Recall:    {metrics_rf[\"recall\"]:.4f}')\n",
    "print(f'   Precision: {metrics_rf[\"precision\"]:.4f}')\n",
    "print(f'   F1 Score:  {metrics_rf[\"f1\"]:.4f}')\n",
    "print(f'   F2 Score:  {metrics_rf[\"f2\"]:.4f}')\n",
    "print(f'   Accuracy:  {metrics_rf[\"accuracy\"]:.4f}')\n",
    "print(f'   PR-AUC:    {metrics_rf[\"pr_auc\"]:.4f}')\n",
    "\n",
    "results['Baseline_RF'] = {'metrics': metrics_rf, 'threshold': threshold_rf}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¥ Step 6: Train KAN Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train KAN base model\nprint('\\n' + '='*70)\nprint('ðŸ”¥ TRAINING KAN BASE MODEL')\nprint('='*70 + '\\n')\n\n# Initialize model\nmodel_kan = KAN(\n    input_dim=X.shape[1],\n    hidden_dim=64,\n    grid_size=5,\n    spline_order=3\n).to(device)\n\noptimizer = optim.AdamW(model_kan.parameters(), lr=0.01, weight_decay=1e-4)\ncriterion = FocalLoss(alpha=0.75, gamma=3.0)\n\n# Learning rate scheduler with warmup\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-5)\n\n# Prepare data loaders\nX_train_tensor = torch.FloatTensor(X_train_resampled).to(device)\ny_train_tensor = torch.FloatTensor(y_train_resampled).unsqueeze(1).to(device)\nX_val_tensor = torch.FloatTensor(X_val).to(device)\n\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\n# Training loop with early stopping\nbest_val_f2 = 0\npatience_counter = 0\nmax_patience = 20\n\nfor epoch in range(100):\n    model_kan.train()\n    epoch_loss = 0\n    \n    for batch_X, batch_y in train_loader:\n        optimizer.zero_grad()\n        outputs = model_kan(batch_X)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    \n    scheduler.step()\n    \n    # Validation\n    model_kan.eval()\n    with torch.no_grad():\n        val_outputs = model_kan(X_val_tensor).cpu().numpy().flatten()\n        val_predictions = (val_outputs >= 0.5).astype(int)\n        val_f2 = fbeta_score(y_val, val_predictions, beta=2, zero_division=0)\n    \n    if val_f2 > best_val_f2:\n        best_val_f2 = val_f2\n        best_model_state = model_kan.state_dict().copy()\n        patience_counter = 0\n    else:\n        patience_counter += 1\n    \n    if (epoch + 1) % 10 == 0:\n        print(f'   Epoch {epoch + 1}/100 - Loss: {epoch_loss/len(train_loader):.4f} - Val F2: {val_f2:.4f} - LR: {scheduler.get_last_lr()[0]:.6f}')\n    \n    if patience_counter >= max_patience:\n        print(f'   Early stopping at epoch {epoch + 1}')\n        model_kan.load_state_dict(best_model_state)\n        break\n\nprint(f'âœ… KAN training complete!')\nprint(f'   Best validation F2: {best_val_f2:.4f}')\n\n# Evaluate on test set\nmodel_kan.eval()\nwith torch.no_grad():\n    y_val_proba_kan = model_kan(X_val_tensor).cpu().numpy().flatten()\n    X_test_tensor = torch.FloatTensor(X_test).to(device)\n    y_test_proba_kan = model_kan(X_test_tensor).cpu().numpy().flatten()\n\nthreshold_kan = find_threshold(y_val, y_val_proba_kan)\nprint(f'   Optimal threshold: {threshold_kan:.2f}')\n\ny_test_pred_kan = (y_test_proba_kan >= threshold_kan).astype(int)\nmetrics_kan = calc_metrics(y_test, y_test_pred_kan, y_test_proba_kan)\n\nprint(f'\\nðŸ“Š Test Set Results:')\nprint(f'   Recall:    {metrics_kan[\"recall\"]:.4f}')\nprint(f'   Precision: {metrics_kan[\"precision\"]:.4f}')\nprint(f'   F1 Score:  {metrics_kan[\"f1\"]:.4f}')\nprint(f'   F2 Score:  {metrics_kan[\"f2\"]:.4f}')\nprint(f'   Accuracy:  {metrics_kan[\"accuracy\"]:.4f}')\nprint(f'   PR-AUC:    {metrics_kan[\"pr_auc\"]:.4f}')\n\nresults['KAN_Base'] = {'metrics': metrics_kan, 'threshold': threshold_kan}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒŸ Step 7: Train KAN + Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train KAN_Attention with ENSEMBLE VOTING - BALANCED EXCELLENCE\nprint('\\n' + '='*70)\nprint('ðŸš€ TRAINING ENSEMBLE KAN_ATTENTION (5 MODELS)')\nprint('ðŸŽ¯ BALANCED MULTI-OBJECTIVE OPTIMIZATION')\nprint('='*70 + '\\n')\n\n# Train 5 models with different random seeds for ensemble\nensemble_models = []\nensemble_seeds = [42, 123, 456, 789, 1024]\n\nfor idx, seed in enumerate(ensemble_seeds):\n    print(f'\\nðŸ”¥ Training Ensemble Model {idx+1}/5 (seed={seed})')\n    print('â”€' * 70)\n    \n    # Set seed for reproducibility\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    \n    # Initialize model\n    model = KAN_Attention(\n        input_dim=X.shape[1],\n        hidden_dim=128,\n        grid_size=5,\n        spline_order=3\n    ).to(device)\n    \n    # Optimizer with slight variations\n    lr = 0.005 if idx < 3 else 0.003  # Different LRs for diversity\n    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-3)\n    \n    # Balanced loss: Mix of Focal and Recall-Focused\n    focal_criterion = FocalLoss(alpha=0.85, gamma=4.0)\n    recall_criterion = RecallFocusedLoss(alpha=0.90, fn_penalty=12.0)\n    \n    # Learning rate scheduler\n    def get_lr(epoch, warmup_epochs=3, total_epochs=100):\n        if epoch < warmup_epochs:\n            return lr * (epoch + 1) / warmup_epochs\n        else:\n            progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)\n            return 1e-5 + (lr - 1e-5) * 0.5 * (1 + np.cos(np.pi * progress))\n    \n    # Training with BALANCED validation metric\n    best_val_score = 0\n    patience_counter = 0\n    max_patience = 20\n    \n    for epoch in range(100):\n        model.train()\n        epoch_loss = 0\n        \n        for batch_X, batch_y in train_loader:\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = get_lr(epoch)\n            \n            optimizer.zero_grad()\n            outputs = model(batch_X)\n            \n            # Combine both losses (60% recall-focused, 40% focal)\n            loss = 0.6 * recall_criterion(outputs, batch_y) + 0.4 * focal_criterion(outputs, batch_y)\n            \n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            epoch_loss += loss.item()\n        \n        # Validation - BALANCED metric (not just recall!)\n        model.eval()\n        with torch.no_grad():\n            val_outputs = model(X_val_tensor).cpu().numpy().flatten()\n            val_predictions = (val_outputs >= 0.3).astype(int)\n            val_metrics = calc_metrics(y_val, val_predictions)\n            \n            # Balanced validation score\n            val_score = (\n                0.35 * val_metrics['recall'] + \n                0.25 * val_metrics['f2'] + \n                0.20 * val_metrics['precision'] + \n                0.20 * val_metrics['accuracy']\n            )\n        \n        if val_score > best_val_score:\n            best_val_score = val_score\n            best_model_state = model.state_dict().copy()\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        if patience_counter >= max_patience:\n            model.load_state_dict(best_model_state)\n            break\n    \n    print(f'   âœ… Model {idx+1} trained - Best Val Score: {best_val_score:.4f}')\n    ensemble_models.append(model)\n\nprint('\\n' + '='*70)\nprint('ðŸŽ¯ ENSEMBLE INFERENCE WITH TEST-TIME AUGMENTATION')\nprint('='*70 + '\\n')\n\n# Test-Time Augmentation: Add small noise to test data\ndef augment_data(X, num_augmentations=3, noise_level=0.01):\n    \"\"\"Generate augmented versions of test data.\"\"\"\n    augmented = [X]\n    for _ in range(num_augmentations - 1):\n        noise = np.random.normal(0, noise_level, X.shape).astype(np.float32)\n        augmented.append(X + noise)\n    return augmented\n\n# Generate augmented validation and test sets\nX_val_augmented = augment_data(X_val, num_augmentations=3)\nX_test_augmented = augment_data(X_test, num_augmentations=3)\n\n# Ensemble prediction with soft voting\nprint('ðŸ“Š Computing ensemble predictions with test-time augmentation...')\n\ndef ensemble_predict(models, X_augmented, device):\n    \"\"\"Soft voting ensemble prediction with augmentation.\"\"\"\n    all_predictions = []\n    \n    for X_aug in X_augmented:\n        X_tensor = torch.FloatTensor(X_aug).to(device)\n        \n        for model in models:\n            model.eval()\n            with torch.no_grad():\n                preds = model(X_tensor).cpu().numpy().flatten()\n                all_predictions.append(preds)\n    \n    # Average all predictions (ensemble + augmentation)\n    ensemble_proba = np.mean(all_predictions, axis=0)\n    return ensemble_proba\n\ny_val_proba_ensemble = ensemble_predict(ensemble_models, X_val_augmented, device)\ny_test_proba_ensemble = ensemble_predict(ensemble_models, X_test_augmented, device)\n\nprint(f'   âœ… Ensemble predictions computed')\nprint(f'   ðŸ“ˆ Total predictions averaged: {len(ensemble_models) * len(X_val_augmented)} per sample')\n\n# BALANCED threshold optimization - THE SECRET SAUCE!\nprint(f'\\nðŸ” Balanced multi-objective threshold optimization...')\nprint(f'   ðŸŽ¯ Target: Recall â‰¥0.875, Accuracy â‰¥0.60, Precision â‰¥0.15')\n\nthreshold_att = find_balanced_threshold(y_val, y_val_proba_ensemble, target_recall=0.875)\n\n# Calculate validation metrics at optimal threshold\ny_val_pred_opt = (y_val_proba_ensemble >= threshold_att).astype(int)\nval_metrics_opt = calc_metrics(y_val, y_val_pred_opt, y_val_proba_ensemble)\n\nprint(f'\\n   âœ… Optimal threshold: {threshold_att:.3f}')\nprint(f'   ðŸ“Š Val Metrics:')\nprint(f'      Recall:    {val_metrics_opt[\"recall\"]:.4f}')\nprint(f'      Precision: {val_metrics_opt[\"precision\"]:.4f}')\nprint(f'      F2:        {val_metrics_opt[\"f2\"]:.4f}')\nprint(f'      Accuracy:  {val_metrics_opt[\"accuracy\"]:.4f}')\n\n# Final test predictions\ny_test_pred_att = (y_test_proba_ensemble >= threshold_att).astype(int)\nmetrics_att = calc_metrics(y_test, y_test_pred_att, y_test_proba_ensemble)\n\nprint(f'\\n{\"=\"*70}')\nprint(f'ðŸ† FINAL BALANCED ENSEMBLE RESULTS - KAN_ATTENTION')\nprint(f'{\"=\"*70}\\n')\nprint(f'   Recall:    {metrics_att[\"recall\"]:.4f} {\"ðŸŽ¯ EXCELLENT!\" if metrics_att[\"recall\"] >= 0.85 else \"\"}')\nprint(f'   Precision: {metrics_att[\"precision\"]:.4f} {\"ðŸ’Ž\" if metrics_att[\"precision\"] >= 0.25 else \"\"}')\nprint(f'   F1 Score:  {metrics_att[\"f1\"]:.4f} {\"â­\" if metrics_att[\"f1\"] >= 0.40 else \"\"}')\nprint(f'   F2 Score:  {metrics_att[\"f2\"]:.4f} {\"â­ EXCELLENT!\" if metrics_att[\"f2\"] >= 0.65 else \"\"}')\nprint(f'   Accuracy:  {metrics_att[\"accuracy\"]:.4f} {\"âœ…\" if metrics_att[\"accuracy\"] >= 0.65 else \"\"}')\nprint(f'   PR-AUC:    {metrics_att[\"pr_auc\"]:.4f} {\"ðŸ†\" if metrics_att[\"pr_auc\"] >= 0.50 else \"\"}')\nprint(f'\\n   Confusion Matrix:')\nprint(f'      TP={metrics_att[\"tp\"]}, FP={metrics_att[\"fp\"]}')\nprint(f'      FN={metrics_att[\"fn\"]}, TN={metrics_att[\"tn\"]}')\nprint(f'\\n   Threshold: {threshold_att:.3f}')\nprint(f'   Ensemble: 5 models Ã— 3 augmentations = 15 predictions')\nprint(f'{\"=\"*70}\\n')\n\n# Compare with Baseline_RF\nprint('ðŸ“Š KAN_Attention vs Baseline_RF:')\nbaseline_recall = 0.875\nbaseline_precision = 0.259\nbaseline_f2 = 0.593\nbaseline_accuracy = 0.682\n\nimprovements = {\n    'Recall': ((metrics_att[\"recall\"] / baseline_recall) - 1) * 100 if baseline_recall > 0 else 0,\n    'Precision': ((metrics_att[\"precision\"] / baseline_precision) - 1) * 100 if baseline_precision > 0 else 0,\n    'F2': ((metrics_att[\"f2\"] / baseline_f2) - 1) * 100 if baseline_f2 > 0 else 0,\n    'Accuracy': ((metrics_att[\"accuracy\"] / baseline_accuracy) - 1) * 100 if baseline_accuracy > 0 else 0\n}\n\nfor metric, improvement in improvements.items():\n    symbol = \"ðŸ“ˆ\" if improvement > 0 else \"ðŸ“‰\"\n    print(f'   {symbol} {metric}: {improvement:+.1f}%')\n\nresults['KAN_Attention'] = {'metrics': metrics_att, 'threshold': threshold_att}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Step 8: Compare Results & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and display final results\n",
    "print('\\n' + '='*70)\n",
    "print('ðŸ“Š FINAL RESULTS - CM1')\n",
    "print('='*70 + '\\n')\n",
    "\n",
    "results_list = []\n",
    "for model_name, data in results.items():\n",
    "    m = data['metrics']\n",
    "    results_list.append({\n",
    "        'dataset': 'CM1',\n",
    "        'model': model_name,\n",
    "        'recall': m['recall'],\n",
    "        'precision': m['precision'],\n",
    "        'f1': m['f1'],\n",
    "        'f2': m['f2'],\n",
    "        'accuracy': m['accuracy'],\n",
    "        'pr_auc': m['pr_auc'],\n",
    "        'threshold': data['threshold']\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Display results\n",
    "print('\\nðŸ“‹ Model Comparison:\\n')\n",
    "for _, row in results_df.iterrows():\n",
    "    print(f\"{row['model']}:\")\n",
    "    print(f\"   Recall:    {row['recall']:.4f} {'ðŸŽ¯' if row['recall'] >= 0.80 else ''}\")\n",
    "    print(f\"   Precision: {row['precision']:.4f}\")\n",
    "    print(f\"   F2 Score:  {row['f2']:.4f} {'â­' if row['f2'] >= 0.75 else ''}\")\n",
    "    print(f\"   Accuracy:  {row['accuracy']:.4f}\")\n",
    "    print(f\"   Threshold: {row['threshold']:.2f}\\n\")\n",
    "\n",
    "# Export results\n",
    "csv_path = os.path.join(OUTPUT_DIR, f'results_{RUN_ID}.csv')\n",
    "json_path = os.path.join(OUTPUT_DIR, f'results_{RUN_ID}.json')\n",
    "\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "results_df.to_json(json_path, orient='records', indent=2)\n",
    "\n",
    "print('\\nðŸ’¾ Results saved to:')\n",
    "print(f'   CSV:  {csv_path}')\n",
    "print(f'   JSON: {json_path}')\n",
    "\n",
    "print('\\n' + '='*70)\n",
    "print('âœ… EXPERIMENT COMPLETE - CM1')\n",
    "print('='*70 + '\\n')\n",
    "\n",
    "# Display summary DataFrame\n",
    "print('\\nðŸ“Š Summary Table:')\n",
    "display(results_df[['model', 'recall', 'precision', 'f1', 'f2', 'accuracy', 'pr_auc']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}