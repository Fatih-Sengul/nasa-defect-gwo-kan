{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Defect Prediction - Meta-Heuristic Feature Selection Pipeline\n",
    "## NASA MDP D'' Dataset - Imbalanced Classification\n",
    "\n",
    "**Author:** Complete Reproducible Experiment\n",
    "\n",
    "**Strategy:**\n",
    "- âœ… RepeatedStratifiedKFold (10x5)\n",
    "- âœ… MCC as Primary Metric\n",
    "- âœ… 3 Baseline Models (RF, XGB, CatBoost)\n",
    "- âœ… Novel: Binary Grey Wolf Optimizer for Feature Selection\n",
    "- âœ… Statistical Testing (Wilcoxon)\n",
    "- âœ… Complete Reproducibility (fixed seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# IMPORTS AND DEPENDENCIES\n# ============================================================================\n\nimport os\nimport glob\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom scipy.io import arff\nfrom scipy.stats import wilcoxon\nfrom io import StringIO\n\n# Machine Learning\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n# Imbalanced Learning - SMOTE EKLENDI!\nfrom imblearn.over_sampling import SMOTE\n\n# Metrics\nfrom sklearn.metrics import (\n    matthews_corrcoef, f1_score, recall_score, roc_auc_score,\n    make_scorer, confusion_matrix\n)\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nwarnings.filterwarnings('ignore')\nsns.set_style('whitegrid')\nsns.set_palette('husl')\n\n# Fixed random seed for reproducibility\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n\nprint(\"[INFO] All dependencies loaded successfully!\")\nprint(f\"[INFO] Random seed: {RANDOM_SEED}\")\nprint(\"[INFO] âœ“ SMOTE (Synthetic Minority Over-sampling) imported!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GOOGLE DRIVE MOUNTING\n",
    "# ============================================================================\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"âœ… Google Drive mounted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATA LOADING\n",
    "# ============================================================================\n",
    "\n",
    "def load_arff_data(file_path):\n",
    "    \"\"\"Load ARFF file and convert to DataFrame\"\"\"\n",
    "    try:\n",
    "        data, meta = arff.loadarff(file_path)\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Decode byte strings\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == object:\n",
    "                try:\n",
    "                    df[col] = df[col].str.decode('utf-8')\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] scipy.io.arff failed: {e}\")\n",
    "        # Fallback: manual parsing\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read()\n",
    "        data_start = content.lower().find('@data')\n",
    "        data_section = content[data_start + 5:].strip()\n",
    "        df = pd.read_csv(StringIO(data_section), header=None)\n",
    "        return df\n",
    "\n",
    "\n",
    "def preprocess_dataset(df, target_col='defective'):\n",
    "    \"\"\"\n",
    "    Preprocess dataset:\n",
    "    - Separate features and target\n",
    "    - Handle missing values\n",
    "    - Convert target to binary (0/1)\n",
    "    \"\"\"\n",
    "    # Assume last column is target\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    \n",
    "    # Convert to numeric\n",
    "    X = X.astype(np.float32)\n",
    "    \n",
    "    # Handle missing values (median imputation)\n",
    "    if np.any(np.isnan(X)):\n",
    "        col_median = np.nanmedian(X, axis=0)\n",
    "        inds = np.where(np.isnan(X))\n",
    "        X[inds] = np.take(col_median, inds[1])\n",
    "    \n",
    "    # Convert target to binary (0 = non-defective, 1 = defective)\n",
    "    if y.dtype == object or y.dtype.name.startswith('str'):\n",
    "        # Map 'true'/'false' or 'Y'/'N' to 1/0\n",
    "        y_clean = []\n",
    "        for val in y:\n",
    "            if isinstance(val, bytes):\n",
    "                val = val.decode('utf-8')\n",
    "            val = str(val).strip().lower()\n",
    "            if val in ['true', 'yes', 'y', '1']:\n",
    "                y_clean.append(1)\n",
    "            else:\n",
    "                y_clean.append(0)\n",
    "        y = np.array(y_clean, dtype=np.int32)\n",
    "    else:\n",
    "        y = y.astype(np.int32)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_datasets(dataset_dir):\n",
    "    \"\"\"\n",
    "    Load all ARFF datasets from directory\n",
    "    Returns: list of (dataset_name, X, y) tuples\n",
    "    \"\"\"\n",
    "    arff_files = glob.glob(os.path.join(dataset_dir, '*.arff'))\n",
    "    \n",
    "    if not arff_files:\n",
    "        raise FileNotFoundError(f\"No ARFF files found in {dataset_dir}\")\n",
    "    \n",
    "    datasets = []\n",
    "    \n",
    "    for file_path in arff_files:\n",
    "        dataset_name = os.path.basename(file_path).replace('.arff', '')\n",
    "        \n",
    "        try:\n",
    "            df = load_arff_data(file_path)\n",
    "            X, y = preprocess_dataset(df)\n",
    "            \n",
    "            print(f\"[LOADED] {dataset_name}: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "            print(f\"         Class distribution: {np.bincount(y)}\")\n",
    "            \n",
    "            datasets.append((dataset_name, X, y))\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to load {dataset_name}: {e}\")\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "\n",
    "print(\"[INFO] Data loading functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# METRICS FUNCTION - F2 SCORE EKLENDI\n# ============================================================================\n\ndef calculate_metrics(y_true, y_pred, y_pred_proba=None):\n    \"\"\"\n    Calculate all required metrics\n    \n    Returns:\n        dict: {MCC, F1, F2, Recall, AUC}\n    \"\"\"\n    from sklearn.metrics import fbeta_score\n    \n    metrics = {}\n    \n    # MCC (Primary Metric)\n    metrics['MCC'] = matthews_corrcoef(y_true, y_pred)\n    \n    # F1-Score\n    metrics['F1'] = f1_score(y_true, y_pred, zero_division=0)\n    \n    # F2-Score (Recall-oriented: beta=2 gives recall 4x more weight than precision)\n    metrics['F2'] = fbeta_score(y_true, y_pred, beta=2.0, zero_division=0)\n    \n    # Recall\n    metrics['Recall'] = recall_score(y_true, y_pred, zero_division=0)\n    \n    # ROC-AUC (if probabilities provided)\n    if y_pred_proba is not None:\n        try:\n            # Handle binary classification\n            if len(np.unique(y_true)) > 1:\n                metrics['AUC'] = roc_auc_score(y_true, y_pred_proba)\n            else:\n                metrics['AUC'] = 0.0\n        except:\n            metrics['AUC'] = 0.0\n    else:\n        metrics['AUC'] = 0.0\n    \n    return metrics\n\n\nprint(\"[INFO] Metrics function ready (with F2-Score)!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# BASELINE MODELS - Ä°YÄ°LEÅžTÄ°RÄ°LMÄ°Åž PARAMETRELER\n# ============================================================================\n\ndef create_baseline_models(n_positive, n_negative):\n    \"\"\"\n    Create baseline models with imbalance handling\n    \n    Ä°YÄ°LEÅžTÄ°RMELER:\n    - Daha fazla estimator\n    - Daha iyi hiperparametreler\n    \n    Args:\n        n_positive: number of positive samples\n        n_negative: number of negative samples\n    \n    Returns:\n        dict: {model_name: model_instance}\n    \"\"\"\n    # Calculate scale_pos_weight for XGBoost\n    scale_pos_weight = n_negative / n_positive if n_positive > 0 else 1.0\n    \n    models = {\n        'Random Forest': RandomForestClassifier(\n            n_estimators=200,  # Increased from 100\n            max_depth=15,      # Added depth control\n            min_samples_split=5,\n            min_samples_leaf=2,\n            class_weight='balanced',\n            random_state=RANDOM_SEED,\n            n_jobs=-1\n        ),\n        \n        'XGBoost': XGBClassifier(\n            n_estimators=200,  # Increased from 100\n            max_depth=6,       # Added depth control\n            learning_rate=0.05, # Lower learning rate\n            subsample=0.8,\n            colsample_bytree=0.8,\n            scale_pos_weight=scale_pos_weight,\n            random_state=RANDOM_SEED,\n            eval_metric='logloss',\n            use_label_encoder=False\n        ),\n        \n        'CatBoost': CatBoostClassifier(\n            iterations=200,    # Increased from 100\n            depth=6,           # Added depth control\n            learning_rate=0.05,\n            auto_class_weights='Balanced',\n            random_seed=RANDOM_SEED,\n            logging_level='Silent',\n            allow_writing_files=False\n        )\n    }\n    \n    return models\n\n\nprint(\"[INFO] Baseline models defined (IMPROVED parameters)!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BINARY GREY WOLF OPTIMIZER (BGWO)\n",
    "# ============================================================================\n",
    "\n",
    "class BinaryGreyWolfOptimizer:\n",
    "    \"\"\"\n",
    "    Binary Grey Wolf Optimizer for Feature Selection\n",
    "    \n",
    "    Optimizes feature subset using GWO with sigmoid transfer function\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_wolves=10, n_iterations=20, random_state=42):\n",
    "        self.n_wolves = n_wolves\n",
    "        self.n_iterations = n_iterations\n",
    "        self.random_state = random_state\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        # Best solutions\n",
    "        self.alpha_pos = None\n",
    "        self.alpha_score = -float('inf')\n",
    "        self.beta_pos = None\n",
    "        self.beta_score = -float('inf')\n",
    "        self.delta_pos = None\n",
    "        self.delta_score = -float('inf')\n",
    "        \n",
    "        self.convergence_curve = []\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"Sigmoid transfer function\"\"\"\n",
    "        return 1.0 / (1.0 + np.exp(-10 * (x - 0.5)))\n",
    "    \n",
    "    def initialize_population(self, n_features):\n",
    "        \"\"\"Initialize binary population\"\"\"\n",
    "        # Start with random feature subsets (30-70% features)\n",
    "        population = np.random.rand(self.n_wolves, n_features) > 0.5\n",
    "        \n",
    "        # Ensure at least 3 features are selected in each wolf\n",
    "        for i in range(self.n_wolves):\n",
    "            if population[i].sum() < 3:\n",
    "                indices = np.random.choice(n_features, 3, replace=False)\n",
    "                population[i, indices] = True\n",
    "        \n",
    "        return population.astype(float)\n",
    "    \n",
    "    def optimize(self, X, y, fitness_func, verbose=True):\n",
    "        \"\"\"\n",
    "        Run BGWO optimization\n",
    "        \n",
    "        Args:\n",
    "            X: feature matrix\n",
    "            y: target vector\n",
    "            fitness_func: function(X_subset, y) -> score\n",
    "            verbose: print progress\n",
    "        \n",
    "        Returns:\n",
    "            best_features: boolean array of selected features\n",
    "            best_score: fitness score\n",
    "        \"\"\"\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        # Initialize population\n",
    "        positions = self.initialize_population(n_features)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n[BGWO] Starting optimization...\")\n",
    "            print(f\"       Wolves: {self.n_wolves}, Iterations: {self.n_iterations}\")\n",
    "        \n",
    "        # Main optimization loop\n",
    "        for iteration in range(self.n_iterations):\n",
    "            # Evaluate fitness for each wolf\n",
    "            for i in range(self.n_wolves):\n",
    "                # Convert to binary mask\n",
    "                feature_mask = positions[i] > 0.5\n",
    "                \n",
    "                # Ensure at least 3 features\n",
    "                if feature_mask.sum() < 3:\n",
    "                    indices = np.random.choice(n_features, 3, replace=False)\n",
    "                    feature_mask[indices] = True\n",
    "                    positions[i] = feature_mask.astype(float)\n",
    "                \n",
    "                # Calculate fitness\n",
    "                try:\n",
    "                    fitness = fitness_func(X[:, feature_mask], y)\n",
    "                except:\n",
    "                    fitness = 0.0\n",
    "                \n",
    "                # Update alpha, beta, delta\n",
    "                if fitness > self.alpha_score:\n",
    "                    self.delta_score = self.beta_score\n",
    "                    self.delta_pos = self.beta_pos.copy() if self.beta_pos is not None else None\n",
    "                    self.beta_score = self.alpha_score\n",
    "                    self.beta_pos = self.alpha_pos.copy() if self.alpha_pos is not None else None\n",
    "                    self.alpha_score = fitness\n",
    "                    self.alpha_pos = positions[i].copy()\n",
    "                elif fitness > self.beta_score:\n",
    "                    self.delta_score = self.beta_score\n",
    "                    self.delta_pos = self.beta_pos.copy() if self.beta_pos is not None else None\n",
    "                    self.beta_score = fitness\n",
    "                    self.beta_pos = positions[i].copy()\n",
    "                elif fitness > self.delta_score:\n",
    "                    self.delta_score = fitness\n",
    "                    self.delta_pos = positions[i].copy()\n",
    "            \n",
    "            # Update coefficient a (linearly decreases from 2 to 0)\n",
    "            a = 2.0 - iteration * (2.0 / self.n_iterations)\n",
    "            \n",
    "            # Update positions\n",
    "            for i in range(self.n_wolves):\n",
    "                for j in range(n_features):\n",
    "                    # Calculate distance to alpha, beta, delta\n",
    "                    r1, r2 = np.random.random(2)\n",
    "                    A1 = 2 * a * r1 - a\n",
    "                    C1 = 2 * r2\n",
    "                    D_alpha = abs(C1 * self.alpha_pos[j] - positions[i, j])\n",
    "                    X1 = self.alpha_pos[j] - A1 * D_alpha\n",
    "                    \n",
    "                    r1, r2 = np.random.random(2)\n",
    "                    A2 = 2 * a * r1 - a\n",
    "                    C2 = 2 * r2\n",
    "                    D_beta = abs(C2 * self.beta_pos[j] - positions[i, j])\n",
    "                    X2 = self.beta_pos[j] - A2 * D_beta\n",
    "                    \n",
    "                    r1, r2 = np.random.random(2)\n",
    "                    A3 = 2 * a * r1 - a\n",
    "                    C3 = 2 * r2\n",
    "                    D_delta = abs(C3 * self.delta_pos[j] - positions[i, j])\n",
    "                    X3 = self.delta_pos[j] - A3 * D_delta\n",
    "                    \n",
    "                    # Update position (average of X1, X2, X3)\n",
    "                    new_pos = (X1 + X2 + X3) / 3.0\n",
    "                    \n",
    "                    # Apply sigmoid and convert to binary\n",
    "                    positions[i, j] = self.sigmoid(new_pos)\n",
    "            \n",
    "            # Store convergence\n",
    "            self.convergence_curve.append(self.alpha_score)\n",
    "            \n",
    "            if verbose and (iteration + 1) % 5 == 0:\n",
    "                n_features_selected = (self.alpha_pos > 0.5).sum()\n",
    "                print(f\"       Iter {iteration + 1}/{self.n_iterations} | \"\n",
    "                      f\"Best MCC: {self.alpha_score:.4f} | \"\n",
    "                      f\"Features: {n_features_selected}/{n_features}\")\n",
    "        \n",
    "        # Final best solution\n",
    "        best_features = self.alpha_pos > 0.5\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n[BGWO] Optimization complete!\")\n",
    "            print(f\"       Best MCC: {self.alpha_score:.4f}\")\n",
    "            print(f\"       Selected: {best_features.sum()}/{n_features} features\")\n",
    "        \n",
    "        return best_features, self.alpha_score\n",
    "\n",
    "\n",
    "print(\"[INFO] Binary GWO implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# META-HEURISTIC FEATURE SELECTION WRAPPER - Ä°YÄ°LEÅžTÄ°RÄ°LMÄ°Åž\n# ============================================================================\n\nclass MetaHeuristicSelector:\n    \"\"\"\n    Meta-Heuristic Feature Selection Wrapper for CatBoost\n    \n    Uses Binary GWO to find optimal feature subset,\n    then trains CatBoost on selected features.\n    \n    Ä°YÄ°LEÅžTÄ°RMELER:\n    - Daha gÃ¼Ã§lÃ¼ BGWO parametreleri (12 wolves, 25 iterations)\n    - Fitness: MCC + F2 kombinasyonu (recall-oriented)\n    - Daha iyi model parametreleri\n    \"\"\"\n    \n    def __init__(self, n_wolves=12, n_iterations=25, random_state=42):\n        self.n_wolves = n_wolves\n        self.n_iterations = n_iterations\n        self.random_state = random_state\n        \n        self.optimizer = None\n        self.selected_features_ = None\n        self.model_ = None\n        self.scaler_ = None\n    \n    def _fitness_function(self, X_subset, y):\n        \"\"\"\n        Fitness function: (MCC + F2) / 2\n        Combines MCC with F2 for recall-oriented optimization\n        \"\"\"\n        from sklearn.model_selection import StratifiedKFold\n        from sklearn.metrics import fbeta_score\n        \n        # Quick 3-fold CV for speed\n        cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=self.random_state)\n        \n        mcc_scores = []\n        f2_scores = []\n        \n        for train_idx, val_idx in cv.split(X_subset, y):\n            X_train, X_val = X_subset[train_idx], X_subset[val_idx]\n            y_train, y_val = y[train_idx], y[val_idx]\n            \n            # Train CatBoost with better parameters\n            model = CatBoostClassifier(\n                iterations=100,  # Increased from 50\n                depth=6,         # Added depth control\n                learning_rate=0.1,\n                auto_class_weights='Balanced',\n                random_seed=self.random_state,\n                logging_level='Silent',\n                allow_writing_files=False\n            )\n            \n            model.fit(X_train, y_train, verbose=False)\n            y_pred = model.predict(X_val)\n            \n            # Calculate MCC and F2\n            mcc = matthews_corrcoef(y_val, y_pred)\n            f2 = fbeta_score(y_val, y_pred, beta=2.0, zero_division=0)\n            \n            mcc_scores.append(mcc)\n            f2_scores.append(f2)\n        \n        # Combined fitness: 60% MCC + 40% F2 (recall-oriented)\n        avg_mcc = np.mean(mcc_scores)\n        avg_f2 = np.mean(f2_scores)\n        \n        return 0.6 * avg_mcc + 0.4 * avg_f2\n    \n    def fit(self, X, y, verbose=True):\n        \"\"\"\n        Fit the selector:\n        1. Run BGWO to find best features\n        2. Train final CatBoost on selected features\n        \"\"\"\n        # Standardize features\n        self.scaler_ = StandardScaler()\n        X_scaled = self.scaler_.fit_transform(X)\n        \n        # Run BGWO with improved parameters\n        self.optimizer = BinaryGreyWolfOptimizer(\n            n_wolves=self.n_wolves,\n            n_iterations=self.n_iterations,\n            random_state=self.random_state\n        )\n        \n        self.selected_features_, best_score = self.optimizer.optimize(\n            X_scaled, y,\n            fitness_func=self._fitness_function,\n            verbose=verbose\n        )\n        \n        # Train final model on selected features with better parameters\n        X_selected = X_scaled[:, self.selected_features_]\n        \n        self.model_ = CatBoostClassifier(\n            iterations=200,  # Increased from 100\n            depth=6,\n            learning_rate=0.05,  # Lower learning rate for better convergence\n            auto_class_weights='Balanced',\n            random_seed=self.random_state,\n            logging_level='Silent',\n            allow_writing_files=False\n        )\n        \n        self.model_.fit(X_selected, y, verbose=False)\n        \n        return self\n    \n    def predict(self, X):\n        \"\"\"Predict using selected features\"\"\"\n        X_scaled = self.scaler_.transform(X)\n        X_selected = X_scaled[:, self.selected_features_]\n        return self.model_.predict(X_selected)\n    \n    def predict_proba(self, X):\n        \"\"\"Predict probabilities using selected features\"\"\"\n        X_scaled = self.scaler_.transform(X)\n        X_selected = X_scaled[:, self.selected_features_]\n        return self.model_.predict_proba(X_selected)[:, 1]\n\n\nprint(\"[INFO] MetaHeuristicSelector implemented (IMPROVED: 12 wolves, 25 iters, MCC+F2 fitness)!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# EXPERIMENT EXECUTION - F2 SCORE + SMOTE EKLENDI\n# ============================================================================\n\ndef run_experiment(dataset_name, X, y, n_splits=10, n_repeats=5, use_smote=True):\n    \"\"\"\n    Run complete experiment:\n    - RepeatedStratifiedKFold CV\n    - SMOTE on training set (each fold)\n    - 3 Baselines + 1 Novel Approach\n    - Store all metrics (including F2)\n    \n    Args:\n        dataset_name: name of the dataset\n        X: feature matrix\n        y: target vector\n        n_splits: number of CV splits\n        n_repeats: number of CV repeats\n        use_smote: whether to apply SMOTE (default: True)\n    \n    Returns:\n        DataFrame with all results\n    \"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(f\"DATASET: {dataset_name}\")\n    print(\"=\"*70)\n    print(f\"Samples: {X.shape[0]}, Features: {X.shape[1]}\")\n    print(f\"Class distribution: {np.bincount(y)}\")\n    \n    if use_smote:\n        print(\"ðŸ”¥ SMOTE ENABLED: Synthetic oversampling will be applied to training sets\")\n    \n    # Calculate class weights\n    n_positive = np.sum(y == 1)\n    n_negative = np.sum(y == 0)\n    \n    # Create baseline models\n    baseline_models = create_baseline_models(n_positive, n_negative)\n    \n    # Add novel approach (with improved parameters)\n    all_models = baseline_models.copy()\n    all_models['BGWO-CatBoost'] = MetaHeuristicSelector(\n        n_wolves=12,      # Improved from 8\n        n_iterations=25,  # Improved from 15\n        random_state=RANDOM_SEED\n    )\n    \n    # Setup CV\n    cv = RepeatedStratifiedKFold(\n        n_splits=n_splits,\n        n_repeats=n_repeats,\n        random_state=RANDOM_SEED\n    )\n    \n    # Store results\n    results = []\n    \n    # Standardize features (for baseline models)\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    \n    # Run CV\n    fold_idx = 0\n    total_folds = n_splits * n_repeats\n    \n    print(f\"\\nRunning {total_folds} folds ({n_splits} splits Ã— {n_repeats} repeats)...\")\n    print(\"-\" * 70)\n    \n    for train_idx, test_idx in cv.split(X, y):\n        fold_idx += 1\n        \n        # Split data\n        X_train_raw, X_test_raw = X[train_idx], X[test_idx]\n        X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n        y_train, y_test = y[train_idx], y[test_idx]\n        \n        # APPLY SMOTE TO TRAINING SET ONLY (avoid data leakage!)\n        if use_smote:\n            # Check if we have enough minority samples for SMOTE\n            min_samples = min(np.bincount(y_train))\n            \n            if min_samples >= 2:  # SMOTE needs at least 2 minority samples\n                try:\n                    # For raw data (MetaHeuristic)\n                    smote_raw = SMOTE(random_state=RANDOM_SEED, k_neighbors=min(5, min_samples-1))\n                    X_train_raw_smote, y_train_smote = smote_raw.fit_resample(X_train_raw, y_train)\n                    \n                    # For scaled data (Baselines)\n                    smote_scaled = SMOTE(random_state=RANDOM_SEED, k_neighbors=min(5, min_samples-1))\n                    X_train_smote, _ = smote_scaled.fit_resample(X_train, y_train)\n                    \n                    # Show SMOTE effect on first fold\n                    if fold_idx == 1:\n                        print(f\"   [SMOTE] Before: {np.bincount(y_train)} â†’ After: {np.bincount(y_train_smote)}\")\n                    \n                    # Use SMOTE'd data\n                    X_train_raw = X_train_raw_smote\n                    X_train = X_train_smote\n                    y_train = y_train_smote\n                    \n                except Exception as e:\n                    if fold_idx == 1:\n                        print(f\"   [SMOTE] Warning: Could not apply SMOTE on fold {fold_idx}: {e}\")\n            else:\n                if fold_idx == 1:\n                    print(f\"   [SMOTE] Skipped: Not enough minority samples ({min_samples})\")\n        \n        # Show progress every 10 folds\n        if fold_idx % 10 == 0 or fold_idx == 1:\n            print(f\"Fold {fold_idx}/{total_folds}...\")\n        \n        # Test each model\n        for model_name, model in all_models.items():\n            try:\n                # For MetaHeuristic, use raw data (it has its own scaler)\n                if model_name == 'BGWO-CatBoost':\n                    # Only show verbose for first fold\n                    verbose = (fold_idx == 1)\n                    model.fit(X_train_raw, y_train, verbose=verbose)\n                    y_pred = model.predict(X_test_raw)\n                    y_pred_proba = model.predict_proba(X_test_raw)\n                else:\n                    # Baseline models use scaled data\n                    model.fit(X_train, y_train)\n                    y_pred = model.predict(X_test)\n                    \n                    # Get probabilities\n                    if hasattr(model, 'predict_proba'):\n                        y_pred_proba = model.predict_proba(X_test)[:, 1]\n                    else:\n                        y_pred_proba = y_pred\n                \n                # Calculate metrics (includes F2 now)\n                metrics = calculate_metrics(y_test, y_pred, y_pred_proba)\n                \n                # Store results\n                result_row = {\n                    'Dataset': dataset_name,\n                    'Model': model_name,\n                    'Fold': fold_idx,\n                    'MCC': metrics['MCC'],\n                    'F1': metrics['F1'],\n                    'F2': metrics['F2'],  # NEW!\n                    'Recall': metrics['Recall'],\n                    'AUC': metrics['AUC']\n                }\n                results.append(result_row)\n                \n            except Exception as e:\n                print(f\"[ERROR] {model_name} failed on fold {fold_idx}: {e}\")\n    \n    print(\"-\" * 70)\n    print(f\"âœ“ Completed {total_folds} folds for {len(all_models)} models\")\n    \n    # Convert to DataFrame\n    results_df = pd.DataFrame(results)\n    \n    return results_df\n\n\nprint(\"[INFO] Experiment function ready (with F2 score + SMOTE)!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# REPORTING & VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def generate_report(results_df):\n",
    "    \"\"\"\n",
    "    Generate summary statistics and visualizations\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Calculate mean and std for each model\n",
    "    summary = results_df.groupby('Model')[['MCC', 'F1', 'Recall', 'AUC']].agg(['mean', 'std'])\n",
    "    \n",
    "    # Flatten column names\n",
    "    summary.columns = ['_'.join(col).strip() for col in summary.columns.values]\n",
    "    \n",
    "    # Sort by MCC (primary metric)\n",
    "    summary = summary.sort_values('MCC_mean', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + summary.to_string())\n",
    "    \n",
    "    # Boxplot\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERATING BOXPLOT...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Boxplot for MCC scores\n",
    "    results_df.boxplot(column='MCC', by='Model', ax=ax, patch_artist=True)\n",
    "    \n",
    "    ax.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('MCC Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('MCC Score Comparison (Primary Metric)', fontsize=14, fontweight='bold')\n",
    "    plt.suptitle('')  # Remove default title\n",
    "    \n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('mcc_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ“ Boxplot saved: mcc_comparison.png\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "def statistical_test(results_df, baseline_model, novel_model):\n",
    "    \"\"\"\n",
    "    Perform Wilcoxon Signed-Rank Test\n",
    "    \n",
    "    Tests if novel approach is significantly better than baseline\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STATISTICAL SIGNIFICANCE TEST\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Baseline: {baseline_model}\")\n",
    "    print(f\"Novel:    {novel_model}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Get MCC scores\n",
    "    baseline_scores = results_df[results_df['Model'] == baseline_model]['MCC'].values\n",
    "    novel_scores = results_df[results_df['Model'] == novel_model]['MCC'].values\n",
    "    \n",
    "    # Wilcoxon test\n",
    "    statistic, p_value = wilcoxon(novel_scores, baseline_scores, alternative='greater')\n",
    "    \n",
    "    print(f\"\\nWilcoxon Signed-Rank Test:\")\n",
    "    print(f\"  Statistic: {statistic:.4f}\")\n",
    "    print(f\"  P-value:   {p_value:.6f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"\\nâœ“ SIGNIFICANT: {novel_model} is significantly better (p < 0.05)\")\n",
    "    else:\n",
    "        print(f\"\\nâœ— NOT SIGNIFICANT: No significant difference (p >= 0.05)\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return statistic, p_value\n",
    "\n",
    "\n",
    "print(\"[INFO] Reporting functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# MAIN EXECUTION - HER DATASET AYRI AYRI Ä°ÅžLENÄ°R + F2 SCORE + SMOTE\n# ============================================================================\n\n# Set dataset directory\nDATASET_DIR = '/content/drive/MyDrive/nasa-defect-gwo-kan/dataset'\n\nprint(\"\\n\" + \"#\"*70)\nprint(\"# SOFTWARE DEFECT PREDICTION - META-HEURISTIC PIPELINE\")\nprint(\"# NASA MDP D'' Dataset - Imbalanced Classification\")\nprint(\"# HER DATASET Ä°Ã‡Ä°N AYRI AYRI SONUÃ‡LAR + F2 SCORE + SMOTE\")\nprint(\"# Ä°YÄ°LEÅžTÄ°RMELER: 12 wolves, 25 iters, MCC+F2 fitness, SMOTE\")\nprint(\"#\"*70)\n\n# Load datasets\nprint(\"\\n[STEP 1] Loading datasets...\")\ndatasets = load_datasets(DATASET_DIR)\n\nprint(f\"\\n[INFO] Loaded {len(datasets)} datasets\")\nprint(f\"[INFO] Her dataset iÃ§in ayrÄ± ayrÄ± iÅŸlem yapÄ±lacak ve sonuÃ§lar gÃ¶sterilecek\")\nprint(f\"[INFO] ðŸ”¥ SMOTE aktif - Training set'lere synthetic oversampling uygulanacak!\")\n\n# Store all results for final summary\nall_results = []\ndataset_summaries = []\n\n# Run experiments on each dataset SEPARATELY\nfor idx, (dataset_name, X, y) in enumerate(datasets, 1):\n    print(\"\\n\" + \"â–ˆ\"*70)\n    print(f\"â–ˆ DATASET {idx}/{len(datasets)}: {dataset_name}\")\n    print(\"â–ˆ\"*70)\n\n    # Skip very small datasets\n    if X.shape[0] < 100:\n        print(f\"\\n[SKIP] {dataset_name}: Too small ({X.shape[0]} samples)\")\n        print(\"â–ˆ\"*70 + \"\\n\")\n        continue\n\n    # Run experiment for this dataset\n    print(f\"\\n[RUNNING] Experiment baÅŸlatÄ±ldÄ±: {dataset_name}\")\n    results_df = run_experiment(dataset_name, X, y, n_splits=10, n_repeats=5, use_smote=True)\n    all_results.append(results_df)\n\n    # IMMEDIATELY show results for THIS dataset\n    print(\"\\n\" + \"â–¼\"*70)\n    print(f\"â–¼ SONUÃ‡LAR: {dataset_name}\")\n    print(\"â–¼\"*70)\n\n    # Calculate summary for this dataset (including F2)\n    summary = results_df.groupby('Model')[['MCC', 'F1', 'F2', 'Recall', 'AUC']].agg(['mean', 'std'])\n    summary.columns = ['_'.join(col).strip() for col in summary.columns.values]\n    summary = summary.sort_values('MCC_mean', ascending=False)\n\n    # Store for final comparison\n    dataset_summaries.append({\n        'dataset': dataset_name,\n        'summary': summary\n    })\n\n    # Print results\n    print(\"\\nðŸ“Š Ã–ZET Ä°STATÄ°STÄ°KLER:\")\n    print(summary.to_string())\n\n    # Find best model for this dataset\n    best_model = summary.index[0]\n    best_mcc = summary.loc[best_model, 'MCC_mean']\n    best_f2 = summary.loc[best_model, 'F2_mean']\n\n    print(f\"\\nðŸ† EN Ä°YÄ° MODEL: {best_model}\")\n    print(f\"   MCC (mean Â± std): {best_mcc:.4f} Â± {summary.loc[best_model, 'MCC_std']:.4f}\")\n    print(f\"   F2  (mean Â± std): {best_f2:.4f} Â± {summary.loc[best_model, 'F2_std']:.4f}\")\n\n    # Show how BGWO-CatBoost performed\n    if 'BGWO-CatBoost' in summary.index:\n        bgwo_mcc = summary.loc['BGWO-CatBoost', 'MCC_mean']\n        bgwo_mcc_std = summary.loc['BGWO-CatBoost', 'MCC_std']\n        bgwo_f2 = summary.loc['BGWO-CatBoost', 'F2_mean']\n        bgwo_f2_std = summary.loc['BGWO-CatBoost', 'F2_std']\n        bgwo_recall = summary.loc['BGWO-CatBoost', 'Recall_mean']\n        bgwo_rank = list(summary.index).index('BGWO-CatBoost') + 1\n\n        print(f\"\\nðŸ”¬ BGWO-CatBoost (Novel Method - IMPROVED + SMOTE):\")\n        print(f\"   MCC    (mean Â± std): {bgwo_mcc:.4f} Â± {bgwo_mcc_std:.4f}\")\n        print(f\"   F2     (mean Â± std): {bgwo_f2:.4f} Â± {bgwo_f2_std:.4f}\")\n        print(f\"   Recall (mean Â± std): {bgwo_recall:.4f} Â± {summary.loc['BGWO-CatBoost', 'Recall_std']:.4f}\")\n        print(f\"   SÄ±ralama: {bgwo_rank}/{len(summary)} model arasÄ±nda\")\n\n    print(\"\\n\" + \"â–ˆ\"*70)\n    print(f\"â–ˆ âœ… TAMAMLANDI: {dataset_name} ({idx}/{len(datasets)})\")\n    print(\"â–ˆ\"*70 + \"\\n\\n\")\n\n# ============================================================================\n# FINAL SUMMARY - ALL DATASETS COMBINED\n# ============================================================================\n\nif len(all_results) > 0:\n    print(\"\\n\" + \"ðŸŽ¯\"*35)\n    print(\"ðŸŽ¯ TÃœM DATASET'LER Ä°Ã‡Ä°N GENEL Ã–ZET\")\n    print(\"ðŸŽ¯\"*35)\n\n    # Combine all results\n    final_results = pd.concat(all_results, ignore_index=True)\n\n    # Overall statistics\n    print(\"\\nðŸ“Š GENEL Ä°STATÄ°STÄ°KLER (TÃ¼m Dataset'ler BirleÅŸtirildi):\")\n    print(\"=\"*70)\n\n    overall_summary = final_results.groupby('Model')[['MCC', 'F1', 'F2', 'Recall', 'AUC']].agg(['mean', 'std'])\n    overall_summary.columns = ['_'.join(col).strip() for col in overall_summary.columns.values]\n    overall_summary = overall_summary.sort_values('MCC_mean', ascending=False)\n\n    print(overall_summary.to_string())\n\n    # Statistical test (compare best baseline vs novel)\n    print(\"\\n\" + \"=\"*70)\n    print(\"ðŸ“ˆ Ä°STATÄ°STÄ°KSEL TEST\")\n    print(\"=\"*70)\n\n    # Find best baseline (highest mean MCC)\n    baseline_models = ['Random Forest', 'XGBoost', 'CatBoost']\n    baseline_means = {}\n    for model in baseline_models:\n        mean_mcc = final_results[final_results['Model'] == model]['MCC'].mean()\n        baseline_means[model] = mean_mcc\n\n    best_baseline = max(baseline_means, key=baseline_means.get)\n\n    print(f\"\\nEn Ä°yi Baseline: {best_baseline} (MCC: {baseline_means[best_baseline]:.4f})\")\n\n    # Test against novel approach\n    if 'BGWO-CatBoost' in final_results['Model'].values:\n        stat, p_val = statistical_test(final_results, best_baseline, 'BGWO-CatBoost')\n\n    # Generate overall boxplot\n    print(\"\\n\" + \"=\"*70)\n    print(\"ðŸ“Š GENEL BOXPLOT OLUÅžTURULUYOR...\")\n    print(\"=\"*70)\n\n    fig, ax = plt.subplots(figsize=(12, 6))\n    final_results.boxplot(column='MCC', by='Model', ax=ax, patch_artist=True)\n    ax.set_xlabel('Model', fontsize=12, fontweight='bold')\n    ax.set_ylabel('MCC Score', fontsize=12, fontweight='bold')\n    ax.set_title('MCC Score Comparison - All Datasets (IMPROVED + SMOTE)', fontsize=14, fontweight='bold')\n    plt.suptitle('')\n    ax.grid(axis='y', alpha=0.3)\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('mcc_comparison_all_datasets_smote.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n    print(\"âœ“ Boxplot kaydedildi: mcc_comparison_all_datasets_smote.png\")\n\n    # F2 boxplot\n    fig, ax = plt.subplots(figsize=(12, 6))\n    final_results.boxplot(column='F2', by='Model', ax=ax, patch_artist=True)\n    ax.set_xlabel('Model', fontsize=12, fontweight='bold')\n    ax.set_ylabel('F2 Score (Recall-oriented)', fontsize=12, fontweight='bold')\n    ax.set_title('F2 Score Comparison - All Datasets (with SMOTE)', fontsize=14, fontweight='bold')\n    plt.suptitle('')\n    ax.grid(axis='y', alpha=0.3)\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('f2_comparison_all_datasets_smote.png', dpi=300, bbox_inches='tight')\n    plt.show()\n\n    print(\"âœ“ F2 Boxplot kaydedildi: f2_comparison_all_datasets_smote.png\")\n\n    # Save results\n    print(\"\\n\" + \"=\"*70)\n    print(\"ðŸ’¾ SONUÃ‡LAR KAYDEDÄ°LÄ°YOR...\")\n    print(\"=\"*70)\n\n    final_results.to_csv('sdp_results_detailed_smote.csv', index=False)\n    print(\"âœ“ DetaylÄ± sonuÃ§lar: sdp_results_detailed_smote.csv\")\n\n    overall_summary.to_csv('sdp_results_summary_smote.csv')\n    print(\"âœ“ Genel Ã¶zet: sdp_results_summary_smote.csv\")\n\n    # Save individual dataset summaries\n    with open('sdp_results_by_dataset_smote.txt', 'w') as f:\n        f.write(\"=\"*70 + \"\\n\")\n        f.write(\"DATASET'E GÃ–RE SONUÃ‡LAR (WITH F2 + SMOTE)\\n\")\n        f.write(\"=\"*70 + \"\\n\\n\")\n\n        for item in dataset_summaries:\n            f.write(f\"\\n{'='*70}\\n\")\n            f.write(f\"Dataset: {item['dataset']}\\n\")\n            f.write(f\"{'='*70}\\n\")\n            f.write(item['summary'].to_string())\n            f.write(\"\\n\\n\")\n\n    print(\"âœ“ Dataset bazlÄ± Ã¶zet: sdp_results_by_dataset_smote.txt\")\n\n    print(\"\\n\" + \"ðŸŽ¯\"*35)\n    print(\"ðŸŽ¯ TÃœM DENEYLER TAMAMLANDI!\")\n    print(\"ðŸŽ¯\"*35)\n\n    print(f\"\\nâœ… Ä°ÅŸlenen Dataset SayÄ±sÄ±: {len(all_results)}\")\n    print(f\"âœ… Toplam Fold SayÄ±sÄ±: {len(final_results)}\")\n    print(f\"âœ… Test Edilen Model SayÄ±sÄ±: {len(overall_summary)}\")\n\n    # Show improvement summary\n    print(\"\\n\" + \"ðŸš€\"*35)\n    print(\"ðŸš€ Ä°YÄ°LEÅžTÄ°RMELER:\")\n    print(\"ðŸš€\"*35)\n    print(\"âœ“ BGWO: 8â†’12 wolves, 15â†’25 iterations\")\n    print(\"âœ“ Fitness: Pure MCC â†’ 60% MCC + 40% F2 (recall-oriented)\")\n    print(\"âœ“ Models: 100â†’200 estimators/iterations\")\n    print(\"âœ“ Metrics: MCC, F1, F2, Recall, AUC\")\n    print(\"âœ“ Hyperparameters: depth control, learning rate optimization\")\n    print(\"âœ“ ðŸ”¥ SMOTE: Synthetic minority oversampling on each training fold\")\n    print(\"ðŸš€\"*35)\n\nelse:\n    print(\"\\n[ERROR] HiÃ§bir dataset iÅŸlenemedi!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}