{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• Advanced Attention-KAN 2025 - SOTA Methods\n",
    "## State-of-the-Art Defect Prediction\n",
    "\n",
    "**Based on Latest Research (2024-2025):**\n",
    "- Multi-Head Self-Attention (Transformer-style)\n",
    "- Dual Attention (Channel + Instance)\n",
    "- TabNet-Style Sparse Feature Selection\n",
    "- Residual Connections + Layer Normalization\n",
    "- Advanced Training: Cosine LR, Label Smoothing, Mixup\n",
    "\n",
    "**Target:** Recall ‚â•90%, Accuracy ‚â•75%, Precision ‚â•45%\n",
    "\n",
    "**Sources:**\n",
    "- [Nature: Hybrid Deep Learning (2024)](https://www.nature.com/articles/s41598-024-65639-4)\n",
    "- [PMC: Attention Feature Extraction (2024)](https://pmc.ncbi.nlm.nih.gov/articles/PMC11996211/)\n",
    "- [PLOS: Attention GRU-LSTM (2024)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0247444)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, warnings, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from io import StringIO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "print(\"‚úÖ Imports ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SOTA 1: MULTI-HEAD SELF-ATTENTION (Transformer-style)\n",
    "# ============================================================================\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    \"\"\"Multi-Head Self-Attention for feature importance\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert in_features % num_heads == 0, \"in_features must be divisible by num_heads\"\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = in_features // num_heads\n",
    "        \n",
    "        # Q, K, V projections\n",
    "        self.qkv = nn.Linear(in_features, in_features * 3)\n",
    "        self.out_proj = nn.Linear(in_features, in_features)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Layer Norm (better than BatchNorm for attention)\n",
    "        self.norm = nn.LayerNorm(in_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Normalize first\n",
    "        x_norm = self.norm(x)\n",
    "        \n",
    "        # Compute Q, K, V\n",
    "        qkv = self.qkv(x_norm).reshape(batch_size, 3, self.num_heads, self.head_dim)\n",
    "        qkv = qkv.permute(1, 0, 2, 3)  # [3, batch, heads, head_dim]\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scale = math.sqrt(self.head_dim)\n",
    "        attn = (q @ k.transpose(-2, -1)) / scale  # [batch, heads, 1, 1]\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        out = (attn @ v).transpose(1, 2).reshape(batch_size, self.in_features)\n",
    "        out = self.out_proj(out)\n",
    "        \n",
    "        # Residual connection\n",
    "        out = out + x\n",
    "        \n",
    "        # Return weighted features and attention weights\n",
    "        return out, attn.mean(dim=1).squeeze()\n",
    "\n",
    "print(\"‚úÖ Multi-Head Self-Attention ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SOTA 2: DUAL ATTENTION (Channel + Instance)\n",
    "# ============================================================================\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"Channel Attention: Which features are important?\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, reduction=4):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features // reduction),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features // reduction, in_features),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch, features]\n",
    "        x_unsq = x.unsqueeze(-1)  # [batch, features, 1]\n",
    "        \n",
    "        avg_out = self.fc(self.avg_pool(x_unsq).squeeze(-1))\n",
    "        max_out = self.fc(self.max_pool(x_unsq).squeeze(-1))\n",
    "        \n",
    "        attn = avg_out + max_out  # Combine\n",
    "        return x * attn, attn\n",
    "\n",
    "\n",
    "class InstanceAttention(nn.Module):\n",
    "    \"\"\"Instance Attention: Which samples are important?\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features // 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch, features]\n",
    "        weights = self.attention(x)  # [batch, 1]\n",
    "        return x * weights, weights\n",
    "\n",
    "\n",
    "class DualAttention(nn.Module):\n",
    "    \"\"\"Dual Attention: Channel + Instance\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, reduction=4):\n",
    "        super().__init__()\n",
    "        self.channel_attn = ChannelAttention(in_features, reduction)\n",
    "        self.instance_attn = InstanceAttention(in_features)\n",
    "        self.norm = nn.LayerNorm(in_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Normalize\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        # Channel attention\n",
    "        x, channel_attn = self.channel_attn(x)\n",
    "        \n",
    "        # Instance attention\n",
    "        x, instance_attn = self.instance_attn(x)\n",
    "        \n",
    "        return x, channel_attn\n",
    "\n",
    "print(\"‚úÖ Dual Attention ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SOTA 3: TABNET-STYLE SPARSE FEATURE SELECTION\n",
    "# ============================================================================\n",
    "\n",
    "class SparseFeatureSelection(nn.Module):\n",
    "    \"\"\"TabNet-inspired sparse feature selector\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, virtual_batch_size=128, momentum=0.02):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        \n",
    "        # Feature transformer\n",
    "        self.transform = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.BatchNorm1d(in_features, momentum=momentum),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Sparse mask generator\n",
    "        self.mask_generator = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features),\n",
    "            nn.BatchNorm1d(in_features, momentum=momentum),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, prior=None):\n",
    "        # Transform features\n",
    "        x_trans = self.transform(x)\n",
    "        \n",
    "        # Generate sparse mask\n",
    "        mask_logits = self.mask_generator(x)\n",
    "        \n",
    "        # Multiply with prior (for sequential attention)\n",
    "        if prior is not None:\n",
    "            mask_logits = mask_logits * prior\n",
    "        \n",
    "        # Sparsemax (more sparse than softmax)\n",
    "        mask = F.softmax(mask_logits, dim=-1)\n",
    "        \n",
    "        # Apply mask\n",
    "        return x_trans * mask, mask\n",
    "\n",
    "print(\"‚úÖ Sparse Feature Selection ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# KAN LAYERS (same as before)\n",
    "# ============================================================================\n",
    "\n",
    "class KANLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, grid_size=5):\n",
    "        super().__init__()\n",
    "        self.grid = nn.Parameter(torch.linspace(-1, 1, grid_size).unsqueeze(0).unsqueeze(0).repeat(out_features, in_features, 1))\n",
    "        self.coef = nn.Parameter(torch.randn(out_features, in_features, grid_size) * 0.1)\n",
    "        self.base_weight = nn.Parameter(torch.randn(out_features, in_features) * 0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        basis = torch.exp(-torch.abs(x.unsqueeze(1).unsqueeze(-1) - self.grid.unsqueeze(0)) ** 2 / 0.5)\n",
    "        return (basis * self.coef.unsqueeze(0)).sum(dim=-1).sum(dim=-1) + torch.matmul(x, self.base_weight.t())\n",
    "\n",
    "print(\"‚úÖ KAN layers ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ADVANCED ATTENTION-KAN 2025 (ALL SOTA COMBINED)\n",
    "# ============================================================================\n",
    "\n",
    "class AdvancedAttentionKAN(nn.Module):\n",
    "    \"\"\"State-of-the-Art KAN with Multiple Attention Mechanisms\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim=64, grid_size=5, num_heads=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Make input_dim divisible by num_heads\n",
    "        self.proj_dim = ((input_dim + num_heads - 1) // num_heads) * num_heads\n",
    "        \n",
    "        # Input projection (if needed)\n",
    "        if input_dim != self.proj_dim:\n",
    "            self.input_proj = nn.Linear(input_dim, self.proj_dim)\n",
    "        else:\n",
    "            self.input_proj = nn.Identity()\n",
    "        \n",
    "        # SOTA 1: Multi-Head Self-Attention\n",
    "        self.multi_head_attn = MultiHeadSelfAttention(self.proj_dim, num_heads)\n",
    "        \n",
    "        # SOTA 2: Dual Attention\n",
    "        self.dual_attn = DualAttention(self.proj_dim)\n",
    "        \n",
    "        # SOTA 3: Sparse Feature Selection\n",
    "        self.sparse_select = SparseFeatureSelection(self.proj_dim)\n",
    "        \n",
    "        # KAN layers with residual connections\n",
    "        self.kan1 = KANLinear(self.proj_dim, hidden_dim, grid_size)\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.kan2 = KANLinear(hidden_dim, hidden_dim // 2, grid_size)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim // 2)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Output\n",
    "        self.output = nn.Linear(hidden_dim // 2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Project input if needed\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        # Multi-Head Self-Attention\n",
    "        x, mh_attn = self.multi_head_attn(x)\n",
    "        \n",
    "        # Dual Attention\n",
    "        x, dual_attn = self.dual_attn(x)\n",
    "        \n",
    "        # Sparse Feature Selection\n",
    "        x, sparse_mask = self.sparse_select(x)\n",
    "        \n",
    "        # KAN layers\n",
    "        x = self.kan1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = F.gelu(x)  # GELU instead of ReLU\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.kan2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Output\n",
    "        x = self.output(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_feature_importance(self, X):\n",
    "        \"\"\"Get combined feature importance from all attention mechanisms\"\"\"\n",
    "        self.eval()\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.FloatTensor(X)\n",
    "        \n",
    "        device = next(self.parameters()).device\n",
    "        X = X.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            X = self.input_proj(X)\n",
    "            _, mh_attn = self.multi_head_attn(X)\n",
    "            _, dual_attn = self.dual_attn(X)\n",
    "            _, sparse_mask = self.sparse_select(X)\n",
    "            \n",
    "            # Combine all attention scores\n",
    "            combined = (mh_attn + dual_attn + sparse_mask) / 3.0\n",
    "            importance = combined.cpu().numpy().mean(axis=0)\n",
    "        \n",
    "        # Project back to original dimension if needed\n",
    "        if self.proj_dim != X.shape[1]:\n",
    "            # Take first input_dim values\n",
    "            importance = importance[:X.shape[1]]\n",
    "        \n",
    "        return importance\n",
    "\n",
    "print(\"‚úÖ Advanced Attention-KAN 2025 ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ADVANCED TRAINING TECHNIQUES\n",
    "# ============================================================================\n",
    "\n",
    "class FocalLossWithLabelSmoothing(nn.Module):\n",
    "    \"\"\"Focal Loss + Label Smoothing\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=3.0, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        # Label smoothing\n",
    "        targets_smooth = targets * (1 - self.smoothing) + self.smoothing * 0.5\n",
    "        \n",
    "        # Focal loss\n",
    "        bce = F.binary_cross_entropy(inputs, targets_smooth, reduction='none')\n",
    "        pt = torch.exp(-bce)\n",
    "        focal = (self.alpha * targets_smooth + (1 - self.alpha) * (1 - targets_smooth)) * (1 - pt) ** self.gamma * bce\n",
    "        \n",
    "        # FN penalty\n",
    "        focal[targets == 1] *= self.pos_weight\n",
    "        \n",
    "        return focal.mean()\n",
    "\n",
    "\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"Mixup data augmentation\"\"\"\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index]\n",
    "    return mixed_x, mixed_y\n",
    "\n",
    "print(\"‚úÖ Advanced loss functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING WITH ADVANCED TECHNIQUES\n",
    "# ============================================================================\n",
    "\n",
    "def train_advanced_model(model, X_train, y_train, X_val, y_val, \n",
    "                        lr=0.001, epochs=50, pos_weight=3.0, warmup_epochs=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X_train_t = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_t = torch.FloatTensor(y_train).unsqueeze(1).to(device)\n",
    "    X_val_t = torch.FloatTensor(X_val).to(device)\n",
    "    y_val_t = torch.FloatTensor(y_val).unsqueeze(1).to(device)\n",
    "    \n",
    "    loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Advanced loss\n",
    "    criterion = FocalLossWithLabelSmoothing(alpha=0.25, gamma=2.0, pos_weight=pos_weight, smoothing=0.1)\n",
    "    \n",
    "    # AdamW optimizer (better than Adam)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    \n",
    "    # Cosine Annealing LR Scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=lr/100)\n",
    "    \n",
    "    best_recall = 0\n",
    "    patience, patience_counter = 15, 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        # Warmup\n",
    "        if epoch < warmup_epochs:\n",
    "            lr_scale = (epoch + 1) / warmup_epochs\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr * lr_scale\n",
    "        \n",
    "        for batch_X, batch_y in loader:\n",
    "            # Mixup augmentation\n",
    "            if np.random.random() < 0.5:\n",
    "                batch_X, batch_y = mixup_data(batch_X, batch_y, alpha=0.2)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "        \n",
    "        # Scheduler step (after warmup)\n",
    "        if epoch >= warmup_epochs:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_out = model(X_val_t)\n",
    "            val_pred = (val_out > 0.5).float().cpu().numpy()\n",
    "            val_recall = recall_score(y_val, val_pred, zero_division=0)\n",
    "        \n",
    "        if val_recall > best_recall:\n",
    "            best_recall = val_recall\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            break\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Advanced training ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading (same as before)\n",
    "def load_arff(file_path):\n",
    "    try:\n",
    "        data, _ = arff.loadarff(file_path)\n",
    "        df = pd.DataFrame(data)\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == object:\n",
    "                try: df[col] = df[col].str.decode('utf-8')\n",
    "                except: pass\n",
    "        return df\n",
    "    except:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read()\n",
    "        return pd.read_csv(StringIO(content[content.lower().find('@data') + 5:].strip()), header=None)\n",
    "\n",
    "def prepare_data(df):\n",
    "    X = df.iloc[:, :-1].values.astype(np.float32)\n",
    "    y = df.iloc[:, -1].values\n",
    "    if y.dtype == object: y = LabelEncoder().fit_transform(y)\n",
    "    else: y = y.astype(np.int32)\n",
    "    if np.any(np.isnan(X)): X[np.where(np.isnan(X))] = np.take(np.nanmedian(X, axis=0), np.where(np.isnan(X))[1])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train, X_test = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "    try: X_train, y_train = SMOTE(sampling_strategy=0.8, random_state=RANDOM_SEED).fit_resample(X_train, y_train)\n",
    "    except: pass\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "print(\"‚úÖ Data loading ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold optimization\n",
    "def find_optimal_threshold(model, X_val, y_val, target_recall=0.90):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_prob = model(torch.FloatTensor(X_val).to(device)).cpu().numpy().flatten()\n",
    "    best_threshold, best_f1 = 0.5, 0\n",
    "    for threshold in np.arange(0.1, 0.7, 0.05):\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        recall = recall_score(y_val, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "        if recall >= target_recall and f1 > best_f1:\n",
    "            best_threshold, best_f1 = threshold, f1\n",
    "    return best_threshold\n",
    "\n",
    "print(\"‚úÖ Threshold optimization ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple GWO\n",
    "class SimpleGWO:\n",
    "    def __init__(self, bounds, fitness_func, n_wolves=6, n_iter=10):\n",
    "        self.bounds = np.array(bounds)\n",
    "        self.fitness_func = fitness_func\n",
    "        self.n_wolves, self.n_iter = n_wolves, n_iter\n",
    "        self.dim = len(bounds)\n",
    "        self.positions = np.random.uniform(self.bounds[:, 0], self.bounds[:, 1], size=(n_wolves, self.dim))\n",
    "        self.alpha_pos, self.alpha_score = np.zeros(self.dim), float('-inf')\n",
    "        self.beta_pos, self.beta_score = np.zeros(self.dim), float('-inf')\n",
    "        self.delta_pos, self.delta_score = np.zeros(self.dim), float('-inf')\n",
    "    def optimize(self):\n",
    "        for it in range(self.n_iter):\n",
    "            for i in range(self.n_wolves):\n",
    "                fitness = self.fitness_func(self.positions[i])\n",
    "                if fitness > self.alpha_score:\n",
    "                    self.delta_score, self.delta_pos = self.beta_score, self.beta_pos.copy()\n",
    "                    self.beta_score, self.beta_pos = self.alpha_score, self.alpha_pos.copy()\n",
    "                    self.alpha_score, self.alpha_pos = fitness, self.positions[i].copy()\n",
    "                elif fitness > self.beta_score:\n",
    "                    self.delta_score, self.delta_pos = self.beta_score, self.beta_pos.copy()\n",
    "                    self.beta_score, self.beta_pos = fitness, self.positions[i].copy()\n",
    "                elif fitness > self.delta_score:\n",
    "                    self.delta_score, self.delta_pos = fitness, self.positions[i].copy()\n",
    "            a = 2 - it * (2.0 / self.n_iter)\n",
    "            for i in range(self.n_wolves):\n",
    "                for j in range(self.dim):\n",
    "                    r1, r2 = np.random.random(2)\n",
    "                    X1 = self.alpha_pos[j] - (2 * a * r1 - a) * abs(2 * r2 * self.alpha_pos[j] - self.positions[i, j])\n",
    "                    r1, r2 = np.random.random(2)\n",
    "                    X2 = self.beta_pos[j] - (2 * a * r1 - a) * abs(2 * r2 * self.beta_pos[j] - self.positions[i, j])\n",
    "                    r1, r2 = np.random.random(2)\n",
    "                    X3 = self.delta_pos[j] - (2 * a * r1 - a) * abs(2 * r2 * self.delta_pos[j] - self.positions[i, j])\n",
    "                    self.positions[i, j] = np.clip((X1 + X2 + X3) / 3.0, self.bounds[j, 0], self.bounds[j, 1])\n",
    "        return self.alpha_pos, self.alpha_score\n",
    "\n",
    "print(\"‚úÖ GWO ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "def plot_importance(model, X_data, dataset_name, top_k=15):\n",
    "    importance = model.get_feature_importance(X_data)\n",
    "    sorted_idx = np.argsort(importance)[::-1][:top_k]\n",
    "    top_imp = importance[sorted_idx]\n",
    "    top_names = [f'F{i}' for i in sorted_idx]\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.barh(range(len(top_imp)), top_imp, color=plt.cm.plasma(top_imp / top_imp.max()))\n",
    "    ax.set_yticks(range(len(top_imp)))\n",
    "    ax.set_yticklabels(top_names)\n",
    "    ax.set_xlabel('Attention Weight', fontweight='bold')\n",
    "    ax.set_title(f'{dataset_name}: Top {top_k} Features (SOTA 2025)', fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    for i, v in enumerate(top_imp):\n",
    "        ax.text(v + 0.01, i, f'{v:.3f}', va='center', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{dataset_name}_sota2025.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualization ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution\n",
    "def run_sota_experiment(dataset_dir='/content/drive/MyDrive/nasa-defect-gwo-kan/dataset'):\n",
    "    files = [f for f in glob.glob(os.path.join(dataset_dir, '*.arff')) \n",
    "             if any(ds in os.path.basename(f).upper() for ds in ['PC1', 'CM1', 'KC1'])]\n",
    "    results = []\n",
    "    \n",
    "    for file_path in files:\n",
    "        dataset_name = os.path.basename(file_path).replace('.arff', '')\n",
    "        print(f\"\\n{'='*60}\\nüöÄ {dataset_name}: SOTA 2025 Training...\\n{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            df = load_arff(file_path)\n",
    "            X_train, X_test, y_train, y_test = prepare_data(df)\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=RANDOM_SEED)\n",
    "            input_dim = X_train.shape[1]\n",
    "            \n",
    "            print(\"üîß GWO optimization...\")\n",
    "            def fitness(params):\n",
    "                try:\n",
    "                    model = AdvancedAttentionKAN(input_dim, int(params[0]), int(params[1]), num_heads=4)\n",
    "                    model = train_advanced_model(model, X_train, y_train, X_val, y_val, params[2], 30, params[3], 5)\n",
    "                    threshold = find_optimal_threshold(model, X_val, y_val, 0.90)\n",
    "                    y_pred = (model(torch.FloatTensor(X_val).to(next(model.parameters()).device)).detach().cpu().numpy().flatten() >= threshold).astype(int)\n",
    "                    return 0.6 * recall_score(y_val, y_pred, zero_division=0) + 0.3 * f1_score(y_val, y_pred, zero_division=0) + 0.1 * accuracy_score(y_val, y_pred)\n",
    "                except: return 0.0\n",
    "            \n",
    "            gwo = SimpleGWO([(48, 128), (4, 8), (0.0005, 0.005), (2.5, 6.0)], fitness, 6, 10)\n",
    "            best_params, _ = gwo.optimize()\n",
    "            hidden_dim, grid_size, lr, pos_weight = int(best_params[0]), int(best_params[1]), best_params[2], best_params[3]\n",
    "            \n",
    "            print(\"ü§ñ Training final model...\")\n",
    "            model = AdvancedAttentionKAN(input_dim, hidden_dim, grid_size, num_heads=4)\n",
    "            model = train_advanced_model(model, X_train, y_train, X_val, y_val, lr, 50, pos_weight, 5)\n",
    "            \n",
    "            print(\"üéØ Finding threshold...\")\n",
    "            threshold = find_optimal_threshold(model, X_val, y_val, 0.90)\n",
    "            \n",
    "            print(\"üìà Evaluating...\")\n",
    "            device = next(model.parameters()).device\n",
    "            y_prob = model(torch.FloatTensor(X_test).to(device)).detach().cpu().numpy().flatten()\n",
    "            y_pred = (y_prob >= threshold).astype(int)\n",
    "            \n",
    "            metrics = {\n",
    "                'Accuracy': accuracy_score(y_test, y_pred),\n",
    "                'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "                'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "                'F1': f1_score(y_test, y_pred, zero_division=0),\n",
    "                'F2': fbeta_score(y_test, y_pred, beta=2, zero_division=0),\n",
    "                'AUC': roc_auc_score(y_test, y_prob) if len(np.unique(y_test)) > 1 else 0\n",
    "            }\n",
    "            \n",
    "            print(\"üìä Creating heatmap...\")\n",
    "            plot_importance(model, X_test, dataset_name, 15)\n",
    "            \n",
    "            results.append({'Dataset': dataset_name, 'Threshold': threshold, **metrics})\n",
    "            print(f\"‚úÖ {dataset_name} complete!\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\\n\")\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    avg = {'Dataset': 'AVERAGE'}\n",
    "    for col in ['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'AUC']:\n",
    "        avg[col] = df[col].mean()\n",
    "    df = pd.concat([df, pd.DataFrame([avg])], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Main execution ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN SOTA 2025!\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî• ADVANCED ATTENTION-KAN 2025 - SOTA METHODS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚ú® Techniques:\")\n",
    "print(\"  1. Multi-Head Self-Attention (4 heads)\")\n",
    "print(\"  2. Dual Attention (Channel + Instance)\")\n",
    "print(\"  3. TabNet-Style Sparse Selection\")\n",
    "print(\"  4. Residual Connections + LayerNorm\")\n",
    "print(\"  5. Cosine Annealing LR + Warmup\")\n",
    "print(\"  6. Label Smoothing + Mixup\")\n",
    "print(\"  7. Gradient Clipping + AdamW\")\n",
    "print(\"\\nüéØ Target: Recall‚â•90%, Accuracy‚â•75%, Precision‚â•45%\\n\")\n",
    "\n",
    "results = run_sota_experiment('/content/drive/MyDrive/nasa-defect-gwo-kan/dataset')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä FINAL RESULTS - SOTA 2025\")\n",
    "print(\"=\"*60)\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "results.to_excel('sota_2025_results.xlsx', index=False)\n",
    "print(\"\\nüíæ Saved: sota_2025_results.xlsx\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ AVERAGE METRICS\")\n",
    "print(\"=\"*60)\n",
    "avg = results[results['Dataset'] == 'AVERAGE'].iloc[0]\n",
    "print(f\"\\n  Accuracy:  {avg['Accuracy']:.4f} {'‚úÖ' if avg['Accuracy'] >= 0.75 else '‚ùå'}\")\n",
    "print(f\"  Precision: {avg['Precision']:.4f} {'‚úÖ' if avg['Precision'] >= 0.45 else '‚ùå'}\")\n",
    "print(f\"  Recall:    {avg['Recall']:.4f} {'‚úÖ' if avg['Recall'] >= 0.90 else '‚ùå'} ‚≠ê\")\n",
    "print(f\"  F1-Score:  {avg['F1']:.4f} {'‚úÖ' if avg['F1'] >= 0.55 else '‚ùå'}\")\n",
    "print(f\"  F2-Score:  {avg['F2']:.4f}\")\n",
    "print(f\"  AUC:       {avg['AUC']:.4f}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ SOTA 2025 COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison Plot\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "fig.suptitle('Advanced Attention-KAN 2025 - SOTA Results', fontsize=16, fontweight='bold')\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'AUC']\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6', '#1abc9c']\n",
    "plot_data = results[results['Dataset'] != 'AVERAGE']\n",
    "for idx, (metric, color) in enumerate(zip(metrics, colors)):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    ax.barh(plot_data['Dataset'], plot_data[metric], color=color, alpha=0.8)\n",
    "    ax.set_xlabel(metric, fontweight='bold', fontsize=12)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    if metric == 'Recall':\n",
    "        ax.axvline(x=0.90, color='red', linestyle='--', linewidth=2, label='Target')\n",
    "        ax.set_facecolor('#ffe6e6')\n",
    "        ax.set_title('‚≠ê PRIMARY ‚≠ê', fontsize=11, color='red', fontweight='bold')\n",
    "    elif metric == 'Accuracy':\n",
    "        ax.axvline(x=0.75, color='darkred', linestyle='--', linewidth=2, alpha=0.6)\n",
    "    elif metric == 'Precision':\n",
    "        ax.axvline(x=0.45, color='darkblue', linestyle='--', linewidth=2, alpha=0.6)\n",
    "    elif metric == 'F1':\n",
    "        ax.axvline(x=0.55, color='darkgreen', linestyle='--', linewidth=2, alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sota_2025_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"üíæ Saved: sota_2025_comparison.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.8.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
