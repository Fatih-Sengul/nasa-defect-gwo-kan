{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Improved Attention-KAN - Clean Output Version\n",
    "## 4 Strategies Combined - Minimal Logging\n",
    "\n",
    "**Target:**\n",
    "- Recall ‚â• 85%\n",
    "- Accuracy ‚â• 70%\n",
    "- Precision ‚â• 40%\n",
    "- F1 ‚â• 50%\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from io import StringIO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "print(\"‚úÖ Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention-KAN Architecture\n",
    "class FeatureAttention(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        hidden = max(in_features // 2, 8)\n",
    "        self.attention = nn.Sequential(nn.Linear(in_features, hidden), nn.ReLU(), nn.Dropout(0.2), nn.Linear(hidden, in_features), nn.Sigmoid())\n",
    "        self.bn = nn.BatchNorm1d(in_features)\n",
    "    def forward(self, x):\n",
    "        return x * self.attention(self.bn(x)), self.attention(self.bn(x))\n",
    "\n",
    "class KANLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, grid_size=5):\n",
    "        super().__init__()\n",
    "        self.grid = nn.Parameter(torch.linspace(-1, 1, grid_size).unsqueeze(0).unsqueeze(0).repeat(out_features, in_features, 1))\n",
    "        self.coef = nn.Parameter(torch.randn(out_features, in_features, grid_size) * 0.1)\n",
    "        self.base_weight = nn.Parameter(torch.randn(out_features, in_features) * 0.1)\n",
    "    def forward(self, x):\n",
    "        basis = torch.exp(-torch.abs(x.unsqueeze(1).unsqueeze(-1) - self.grid.unsqueeze(0)) ** 2 / 0.5)\n",
    "        return (basis * self.coef.unsqueeze(0)).sum(dim=-1).sum(dim=-1) + torch.matmul(x, self.base_weight.t())\n",
    "\n",
    "class AttentionKAN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, grid_size=5):\n",
    "        super().__init__()\n",
    "        self.attention = FeatureAttention(input_dim)\n",
    "        self.kan1 = KANLinear(input_dim, hidden_dim, grid_size)\n",
    "        self.kan2 = KANLinear(hidden_dim, hidden_dim // 2, grid_size)\n",
    "        self.output = nn.Linear(hidden_dim // 2, 1)\n",
    "        self.bn1, self.bn2 = nn.BatchNorm1d(hidden_dim), nn.BatchNorm1d(hidden_dim // 2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.attention(x)\n",
    "        x = self.dropout(torch.relu(self.bn1(self.kan1(x))))\n",
    "        x = self.dropout(torch.relu(self.bn2(self.kan2(x))))\n",
    "        return torch.sigmoid(self.output(x))\n",
    "    def get_feature_importance(self, X):\n",
    "        self.eval()\n",
    "        if not isinstance(X, torch.Tensor): X = torch.FloatTensor(X)\n",
    "        with torch.no_grad():\n",
    "            _, weights = self.attention(X.to(next(self.parameters()).device))\n",
    "        return weights.cpu().numpy().mean(axis=0)\n",
    "\n",
    "print(\"‚úÖ Architecture ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=3.0):\n",
    "        super().__init__()\n",
    "        self.alpha, self.gamma, self.pos_weight = alpha, gamma, pos_weight\n",
    "    def forward(self, inputs, targets):\n",
    "        bce = nn.functional.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        focal = (targets * self.alpha + (1 - targets) * (1 - self.alpha)) * (1 - torch.exp(-bce)) ** self.gamma * bce\n",
    "        focal[targets == 1] *= self.pos_weight\n",
    "        return focal.mean()\n",
    "\n",
    "print(\"‚úÖ Focal Loss ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training (silent mode)\n",
    "def train_model(model, X_train, y_train, X_val, y_val, lr=0.01, epochs=30, pos_weight=3.0):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    X_train_t = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_t = torch.FloatTensor(y_train).unsqueeze(1).to(device)\n",
    "    X_val_t = torch.FloatTensor(X_val).to(device)\n",
    "    y_val_t = torch.FloatTensor(y_val).unsqueeze(1).to(device)\n",
    "    \n",
    "    loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=32, shuffle=True)\n",
    "    criterion = FocalLoss(alpha=0.25, gamma=2.0, pos_weight=pos_weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    best_recall = 0\n",
    "    patience, patience_counter = 10, 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            criterion(model(batch_X), batch_y).backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_recall = recall_score(y_val, (model(X_val_t) > 0.5).float().cpu().numpy(), zero_division=0)\n",
    "        \n",
    "        if val_recall > best_recall:\n",
    "            best_recall = val_recall\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            break\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Training ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold Optimization (silent)\n",
    "def find_optimal_threshold(model, X_val, y_val, target_recall=0.85):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_prob = model(torch.FloatTensor(X_val).to(device)).cpu().numpy().flatten()\n",
    "    \n",
    "    best_threshold, best_f1 = 0.5, 0\n",
    "    for threshold in np.arange(0.1, 0.7, 0.05):\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        recall = recall_score(y_val, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "        if recall >= target_recall and f1 > best_f1:\n",
    "            best_threshold, best_f1 = threshold, f1\n",
    "    return best_threshold\n",
    "\n",
    "print(\"‚úÖ Threshold optimization ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "def load_arff(file_path):\n",
    "    try:\n",
    "        data, _ = arff.loadarff(file_path)\n",
    "        df = pd.DataFrame(data)\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == object:\n",
    "                try: df[col] = df[col].str.decode('utf-8')\n",
    "                except: pass\n",
    "        return df\n",
    "    except:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read()\n",
    "        return pd.read_csv(StringIO(content[content.lower().find('@data') + 5:].strip()), header=None)\n",
    "\n",
    "def prepare_data(df):\n",
    "    X = df.iloc[:, :-1].values.astype(np.float32)\n",
    "    y = df.iloc[:, -1].values\n",
    "    if y.dtype == object or y.dtype.name.startswith('str'): y = LabelEncoder().fit_transform(y)\n",
    "    else: y = y.astype(np.int32)\n",
    "    if np.any(np.isnan(X)): X[np.where(np.isnan(X))] = np.take(np.nanmedian(X, axis=0), np.where(np.isnan(X))[1])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train, X_test = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "    \n",
    "    try: X_train, y_train = SMOTE(sampling_strategy=0.8, random_state=RANDOM_SEED).fit_resample(X_train, y_train)\n",
    "    except: pass\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "print(\"‚úÖ Data loading ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GWO (minimal logging)\n",
    "class SimpleGWO:\n",
    "    def __init__(self, bounds, fitness_func, n_wolves=6, n_iter=8):\n",
    "        self.bounds = np.array(bounds)\n",
    "        self.fitness_func = fitness_func\n",
    "        self.n_wolves, self.n_iter = n_wolves, n_iter\n",
    "        self.dim = len(bounds)\n",
    "        self.positions = np.random.uniform(self.bounds[:, 0], self.bounds[:, 1], size=(n_wolves, self.dim))\n",
    "        self.alpha_pos, self.alpha_score = np.zeros(self.dim), float('-inf')\n",
    "        self.beta_pos, self.beta_score = np.zeros(self.dim), float('-inf')\n",
    "        self.delta_pos, self.delta_score = np.zeros(self.dim), float('-inf')\n",
    "    \n",
    "    def optimize(self):\n",
    "        for it in range(self.n_iter):\n",
    "            for i in range(self.n_wolves):\n",
    "                fitness = self.fitness_func(self.positions[i])\n",
    "                if fitness > self.alpha_score:\n",
    "                    self.delta_score, self.delta_pos = self.beta_score, self.beta_pos.copy()\n",
    "                    self.beta_score, self.beta_pos = self.alpha_score, self.alpha_pos.copy()\n",
    "                    self.alpha_score, self.alpha_pos = fitness, self.positions[i].copy()\n",
    "                elif fitness > self.beta_score:\n",
    "                    self.delta_score, self.delta_pos = self.beta_score, self.beta_pos.copy()\n",
    "                    self.beta_score, self.beta_pos = fitness, self.positions[i].copy()\n",
    "                elif fitness > self.delta_score:\n",
    "                    self.delta_score, self.delta_pos = fitness, self.positions[i].copy()\n",
    "            \n",
    "            a = 2 - it * (2.0 / self.n_iter)\n",
    "            for i in range(self.n_wolves):\n",
    "                for j in range(self.dim):\n",
    "                    r1, r2 = np.random.random(2)\n",
    "                    X1 = self.alpha_pos[j] - (2 * a * r1 - a) * abs(2 * r2 * self.alpha_pos[j] - self.positions[i, j])\n",
    "                    r1, r2 = np.random.random(2)\n",
    "                    X2 = self.beta_pos[j] - (2 * a * r1 - a) * abs(2 * r2 * self.beta_pos[j] - self.positions[i, j])\n",
    "                    r1, r2 = np.random.random(2)\n",
    "                    X3 = self.delta_pos[j] - (2 * a * r1 - a) * abs(2 * r2 * self.delta_pos[j] - self.positions[i, j])\n",
    "                    self.positions[i, j] = np.clip((X1 + X2 + X3) / 3.0, self.bounds[j, 0], self.bounds[j, 1])\n",
    "        \n",
    "        return self.alpha_pos, self.alpha_score\n",
    "\n",
    "print(\"‚úÖ GWO ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini Ensemble\n",
    "def train_ensemble(X_train, y_train, X_val, y_val, input_dim, hidden_dim, grid_size, lr, pos_weight):\n",
    "    models = []\n",
    "    for seed in [42, 123]:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        model = AttentionKAN(input_dim, hidden_dim, grid_size)\n",
    "        models.append(train_model(model, X_train, y_train, X_val, y_val, lr, 30, pos_weight))\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    return models\n",
    "\n",
    "def ensemble_predict(models, X_test, threshold=0.5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    X_t = torch.FloatTensor(X_test).to(device)\n",
    "    preds = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds.append(model(X_t).cpu().numpy().flatten())\n",
    "    avg_prob = np.mean(preds, axis=0)\n",
    "    return (avg_prob >= threshold).astype(int), avg_prob\n",
    "\n",
    "print(\"‚úÖ Ensemble ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "def plot_importance(model, X_data, dataset_name, top_k=15):\n",
    "    importance = model.get_feature_importance(X_data)\n",
    "    sorted_idx = np.argsort(importance)[::-1][:top_k]\n",
    "    top_imp = importance[sorted_idx]\n",
    "    top_names = [f'F{i}' for i in sorted_idx]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.barh(range(len(top_imp)), top_imp, color=plt.cm.viridis(top_imp / top_imp.max()))\n",
    "    ax.set_yticks(range(len(top_imp)))\n",
    "    ax.set_yticklabels(top_names)\n",
    "    ax.set_xlabel('Attention Weight', fontweight='bold')\n",
    "    ax.set_title(f'{dataset_name}: Top {top_k} Features', fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    for i, v in enumerate(top_imp):\n",
    "        ax.text(v + 0.01, i, f'{v:.3f}', va='center', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{dataset_name}_clean.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualization ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution (CLEAN OUTPUT)\n",
    "def run_experiment(dataset_dir='/content/drive/MyDrive/nasa-defect-gwo-kan/dataset'):\n",
    "    files = [f for f in glob.glob(os.path.join(dataset_dir, '*.arff')) \n",
    "             if any(ds in os.path.basename(f).upper() for ds in ['PC1', 'CM1', 'KC1'])]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for file_path in files:\n",
    "        dataset_name = os.path.basename(file_path).replace('.arff', '')\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üìä {dataset_name}: Training started...\")\n",
    "        print('='*60)\n",
    "        \n",
    "        try:\n",
    "            # Load\n",
    "            df = load_arff(file_path)\n",
    "            X_train, X_test, y_train, y_test = prepare_data(df)\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=RANDOM_SEED)\n",
    "            input_dim = X_train.shape[1]\n",
    "            \n",
    "            # GWO\n",
    "            print(\"üîß Optimizing hyperparameters...\")\n",
    "            def fitness(params):\n",
    "                try:\n",
    "                    model = AttentionKAN(input_dim, int(params[0]), int(params[1]))\n",
    "                    model = train_model(model, X_train, y_train, X_val, y_val, params[2], 20, params[3])\n",
    "                    threshold = find_optimal_threshold(model, X_val, y_val, 0.85)\n",
    "                    y_pred = (model(torch.FloatTensor(X_val).to(next(model.parameters()).device)).detach().cpu().numpy().flatten() >= threshold).astype(int)\n",
    "                    return 0.5 * recall_score(y_val, y_pred, zero_division=0) + 0.3 * f1_score(y_val, y_pred, zero_division=0) + 0.2 * accuracy_score(y_val, y_pred)\n",
    "                except:\n",
    "                    return 0.0\n",
    "            \n",
    "            gwo = SimpleGWO([(32, 96), (3, 7), (0.005, 0.02), (2.0, 5.0)], fitness, 6, 8)\n",
    "            best_params, _ = gwo.optimize()\n",
    "            hidden_dim, grid_size, lr, pos_weight = int(best_params[0]), int(best_params[1]), best_params[2], best_params[3]\n",
    "            \n",
    "            # Train ensemble\n",
    "            print(\"ü§ñ Training ensemble...\")\n",
    "            models = train_ensemble(X_train, y_train, X_val, y_val, input_dim, hidden_dim, grid_size, lr, pos_weight)\n",
    "            \n",
    "            # Find threshold\n",
    "            print(\"üéØ Optimizing threshold...\")\n",
    "            X_val_t = torch.FloatTensor(X_val).to(next(models[0].parameters()).device)\n",
    "            val_preds = [m(X_val_t).detach().cpu().numpy().flatten() for m in models]\n",
    "            val_avg = np.mean(val_preds, axis=0)\n",
    "            best_threshold = 0.5\n",
    "            best_f1 = 0\n",
    "            for t in np.arange(0.1, 0.7, 0.05):\n",
    "                y_pred = (val_avg >= t).astype(int)\n",
    "                if recall_score(y_val, y_pred, zero_division=0) >= 0.85:\n",
    "                    f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "                    if f1 > best_f1:\n",
    "                        best_threshold, best_f1 = t, f1\n",
    "            \n",
    "            # Test\n",
    "            print(\"üìà Evaluating...\")\n",
    "            y_pred, y_prob = ensemble_predict(models, X_test, best_threshold)\n",
    "            metrics = {\n",
    "                'Accuracy': accuracy_score(y_test, y_pred),\n",
    "                'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "                'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "                'F1': f1_score(y_test, y_pred, zero_division=0),\n",
    "                'F2': fbeta_score(y_test, y_pred, beta=2, zero_division=0),\n",
    "                'AUC': roc_auc_score(y_test, y_prob) if len(np.unique(y_test)) > 1 else 0\n",
    "            }\n",
    "            \n",
    "            # Visualize\n",
    "            print(\"üìä Creating heatmap...\")\n",
    "            plot_importance(models[0], X_test, dataset_name, 15)\n",
    "            \n",
    "            results.append({'Dataset': dataset_name, 'Threshold': best_threshold, **metrics})\n",
    "            print(f\"‚úÖ {dataset_name} complete!\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\\n\")\n",
    "    \n",
    "    # Summary\n",
    "    df = pd.DataFrame(results)\n",
    "    avg = {'Dataset': 'AVERAGE'}\n",
    "    for col in ['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'AUC']:\n",
    "        avg[col] = df[col].mean()\n",
    "    df = pd.concat([df, pd.DataFrame([avg])], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Ready to run!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN!\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ IMPROVED ATTENTION-KAN - 4 STRATEGIES\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüéØ Target: Recall‚â•85%, Accuracy‚â•70%, Precision‚â•40%, F1‚â•50%\\n\")\n",
    "\n",
    "results = run_experiment('/content/drive/MyDrive/nasa-defect-gwo-kan/dataset')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "results.to_excel('improved_clean_results.xlsx', index=False)\n",
    "print(\"\\nüíæ Saved: improved_clean_results.xlsx\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ AVERAGE METRICS\")\n",
    "print(\"=\"*60)\n",
    "avg = results[results['Dataset'] == 'AVERAGE'].iloc[0]\n",
    "print(f\"\\n  Accuracy:  {avg['Accuracy']:.4f} {'‚úÖ' if avg['Accuracy'] >= 0.70 else '‚ùå'}\")\n",
    "print(f\"  Precision: {avg['Precision']:.4f} {'‚úÖ' if avg['Precision'] >= 0.40 else '‚ùå'}\")\n",
    "print(f\"  Recall:    {avg['Recall']:.4f} {'‚úÖ' if avg['Recall'] >= 0.85 else '‚ùå'} ‚≠ê\")\n",
    "print(f\"  F1-Score:  {avg['F1']:.4f} {'‚úÖ' if avg['F1'] >= 0.50 else '‚ùå'}\")\n",
    "print(f\"  F2-Score:  {avg['F2']:.4f}\")\n",
    "print(f\"  AUC:       {avg['AUC']:.4f}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison Plot\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "fig.suptitle('Improved Attention-KAN Results', fontsize=16, fontweight='bold')\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'AUC']\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6', '#1abc9c']\n",
    "plot_data = results[results['Dataset'] != 'AVERAGE']\n",
    "for idx, (metric, color) in enumerate(zip(metrics, colors)):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    ax.barh(plot_data['Dataset'], plot_data[metric], color=color, alpha=0.7)\n",
    "    ax.set_xlabel(metric, fontweight='bold')\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    if metric == 'Recall':\n",
    "        ax.axvline(x=0.85, color='red', linestyle='--', linewidth=2)\n",
    "        ax.set_facecolor('#ffe6e6')\n",
    "        ax.set_title('‚≠ê PRIMARY ‚≠ê', fontsize=10, color='red')\n",
    "    elif metric == 'Accuracy':\n",
    "        ax.axvline(x=0.70, color='blue', linestyle='--', linewidth=2, alpha=0.5)\n",
    "    elif metric == 'Precision':\n",
    "        ax.axvline(x=0.40, color='orange', linestyle='--', linewidth=2, alpha=0.5)\n",
    "    elif metric == 'F1':\n",
    "        ax.axvline(x=0.50, color='purple', linestyle='--', linewidth=2, alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('improved_clean_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"üíæ Saved: improved_clean_comparison.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.8.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
